<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>深度学习入门 Day 1 | KEEP IT REAL</title>
<meta name="keywords" content="DeepLearning, Python, CNN, 深度学习">
<meta name="description" content="从零开始学习深度学习">
<meta name="author" content="why">
<link rel="canonical" href="https://hy4real.github.io/posts/deeplearningday1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css" integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn&#43;yY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://hy4real.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hy4real.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hy4real.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hy4real.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://hy4real.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://hy4real.github.io/posts/deeplearningday1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://hy4real.github.io/posts/deeplearningday1/">
  <meta property="og:site_name" content="KEEP IT REAL">
  <meta property="og:title" content="深度学习入门 Day 1">
  <meta property="og:description" content="从零开始学习深度学习">
  <meta property="og:locale" content="zh">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-11-09T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-11-09T00:00:00+00:00">
    <meta property="article:tag" content="DeepLearning">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="CNN">
    <meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习入门 Day 1">
<meta name="twitter:description" content="从零开始学习深度学习">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://hy4real.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "深度学习入门 Day 1",
      "item": "https://hy4real.github.io/posts/deeplearningday1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "深度学习入门 Day 1",
  "name": "深度学习入门 Day 1",
  "description": "从零开始学习深度学习",
  "keywords": [
    "DeepLearning", "Python", "CNN", "深度学习"
  ],
  "articleBody": " 一、整体概述 这是一个完整的MNIST手写数字分类项目，使用PyTorch构建了一个小型卷积神经网络(CNN)。代码实现了数据加载、模型训练、测试评估、可视化错误样本和日志记录的全流程，非常适合作为深度学习入门范例。\n二、逐部分详细解析 1. 导入库 (Lines 1-7) import torch, torchvision, time, os from torch import nn from torch.utils.data import DataLoader from torchvision import datasets, transforms from torch.utils.tensorboard import SummaryWriter import random, numpy as np import matplotlib.pyplot as plt 功能：导入所有必需的工具库。\n设计意图：\ntorch \u0026 torchvision: PyTorch核心框架和计算机视觉工具 time, os: 基础系统功能（虽然代码中没直接用，但为扩展预留） SummaryWriter: 连接TensorBoard，实时可视化训练曲线 random, numpy: 用于设置随机种子，保证结果可复现 matplotlib: 绘制错误样本图，直观观察模型弱点 2. 随机种子设置 (Lines 9-16) seed = 42 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) # CPU 权重 torch.cuda.manual_seed(seed) # GPU 权重 torch.cuda.manual_seed_all(seed) # 多 GPU torch.backends.cudnn.deterministic = True # 卷积确定 torch.backends.cudnn.benchmark = False device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") print(\"Using\", device) 功能：强制所有随机性来源产生确定性结果，并自动选择运算设备。\n意图详解：\n可复现性：深度学习实验依赖大量随机初始化，不设置种子的话，每次运行结果都不同，无法对比调参效果 多层保险：分别设置Python、numpy、PyTorch CPU/GPU的随机种子，确保无死角 cuDNN设置： deterministic = True: 牺牲一点速度，确保卷积等操作的算法是确定的 benchmark = False: 禁止自动选择最优算法，避免非确定性 设备选择：自动检测GPU，有则用GPU加速，无则 fallback 到CPU，提升代码兼容性 3. 超参数配置 (Lines 18-21) BATCH_SIZE = 128 EPOCHS = 5 LR = 0.1 功能：集中管理训练参数。\n在这个参数配置下，准确率达到了99.05%。\n4. 数据加载与预处理 (Lines 23-35) tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) train_ds = datasets.MNIST(root='data', train=True, download=True, transform=tf) test_ds = datasets.MNIST(root='data', train=False, download=True, transform=tf) # FIX-1: num_workers=0 禁用多进程 train_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True) test_ld = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True) 功能：下载数据集，转换格式，封装成可迭代的数据加载器。\n逐行拆解：\ntransforms.ToTensor(): 将PIL图片(0-255)转为PyTorch张量(0.0-1.0)，并调整维度为[C, H, W] transforms.Normalize((0.1307,), (0.3081,)): 关键步骤，对数据进行标准化 0.1307 是MNIST训练集的均值，0.3081 是标准差 意图：让数据分布接近标准正态分布，加速训练收敛，提升稳定性 为什么是单值？因为MNIST是灰度图，单通道；彩色图会是3个值如(0.5,0.5,0.5) datasets.MNIST(...): 自动从网络下载数据集到./data文件夹 DataLoader : shuffle=True: 训练集打乱顺序，避免模型学到顺序偏见 num_workers=0 : Windows系统下的重要修复。多进程加载数据在Windows上容易因fork机制崩溃，设为0可确保稳定 pin_memory=True: 将数据锁页在内存，加速向GPU的传输 5. 模型定义 (Lines 37-48) class Net(nn.Module): def __init__(self): super().__init__() self.features = nn.Sequential( nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2) ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(64*7*7, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 10) ) def forward(self, x): return self.classifier(self.features(x)) 功能：定义一个简洁高效的CNN架构。\n结构解析：\nself.features : 特征提取层 Conv2d(1,32,3,padding=1): 输入1通道(灰度)，输出32通道，3x3卷积，padding=1保持尺寸不变 MaxPool2d(2): 2x2最大池化，尺寸减半（28x28 → 14x14） Conv2d(32,64,3,padding=1): 通道数升维到64 第二次池化后尺寸: 14x14 → 7x7 self.classifier : 分类头 nn.Flatten(): 展平特征图，64*7*7 = 3136个特征 nn.Linear(3136,128): 全连接层降维到128 nn.Dropout(0.2): 防止过拟合，训练时随机丢弃20%神经元 nn.Linear(128,10): 输出10个类别得分（对应数字0-9） 意图：这是经典的LeNet现代化变体，结构清晰，参数少（约20万），在MNIST上足够强大且训练快速。\n6. 训练函数 (Lines 50-61) def train(epoch, model, criterion, optimizer, writer): model.train() for batch_idx, (x, y) in enumerate(train_ld): x, y = x.to(device), y.to(device) optimizer.zero_grad() loss = criterion(model(x), y) loss.backward() optimizer.step() scheduler.step() if batch_idx % 100 == 0: print(f'Epoch {epoch} [{batch_idx*len(x)}/{len(train_ld.dataset)}] ' f'Loss: {loss.item():.4f}') writer.add_scalar('train/loss', loss.item(), epoch*len(train_ld)+batch_idx) 功能：执行一个训练轮次，更新模型权重。\n流程详解：\nmodel.train(): 开启训练模式（启用Dropout等） 遍历train_ld，每次取BATCH_SIZE个样本 x.to(device): 把数据搬到GPU/CPU optimizer.zero_grad(): 清空梯度，防止梯度累积 criterion(model(x), y): 前向传播+计算交叉熵损失 loss.backward(): 反向传播，计算梯度 optimizer.step(): 根据梯度更新权重 scheduler.step(): 调整学习率（每个batch都调，注意：通常按epoch调更常见，但这样也行） 每100个batch打印日志，并写入TensorBoard（全局步数=epoch*总batch数+当前batch数） 意图：标准的训练循环，代码紧凑，注释清晰，适合教学。\n7. 测试函数 (Lines 63-98) @torch.no_grad() def test(epoch, model, writer, test_ld, device): model.eval() correct, total = 0, 0 wrong_samples = [] # 存储错误样本的特征（x） wrong_labels = [] # 存储错误样本的真实标签（y） wrong_preds = [] # 存储错误样本的预测标签（pred） # ... 遍历测试集 ... if len(wrong_samples) \u003e= 9: plt.figure(figsize=(9, 9)) for i in range(9): img = wrong_samples[i].squeeze() plt.subplot(3, 3, i + 1) plt.imshow(img, cmap='gray') plt.title(f'T:{label} P:{guess}') plt.axis('off') plt.savefig('wrong_cases.png', dpi=120) plt.close() 功能：评估模型性能，并可视化典型错误样本。\n亮点解析：\n@torch.no_grad() : 性能优化，禁用梯度计算，节省内存，提速30%以上 model.eval(): 切换到评估模式（关闭Dropout） 错误样本收集：这是本代码的核心价值之一 只收集9个错误样本，避免内存爆炸 用nonzero(as_tuple=True)[0]找到预测≠真实的索引 存储原始图像、真实标签、预测标签到CPU，便于后续绘图 可视化：绘制3x3网格，展示模型最容易混淆的手写数字 squeeze(): 去除通道维度（1,28,28 → 28,28） cmap='gray': 灰度图显示 plt.close(): 防止内存泄漏，释放图形资源 日志记录：将准确率写入TensorBoard 意图：不仅输出数字指标，还让开发者直观理解模型弱点（比如是7被认成9，还是3被认成8），指导后续改进方向。\n8. 主程序保护壳 (Lines 100-110) if __name__ == '__main__': from torch.optim.lr_scheduler import CosineAnnealingLR model = Net().to(device) criterion = nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS) writer = SummaryWriter('runs') for ep in range(1, EPOCHS+1): train(ep, model, criterion, optimizer, writer) test(ep, model, writer, test_ld, device) torch.save(model.state_dict(), 'mnist_cnn.pt') writer.close() 功能：组织训练流程，保存结果。\n关键点：\nif __name__ == '__main__' : Windows多进程必备。没有这个，在Windows上运行会报错或产生僵尸进程 学习率调度器：CosineAnnealingLR实现余弦退火 学习率从初始值平滑下降到接近0，像cos曲线 意图：前期快速探索，后期精细调整， often 比固定学习率效果好 注意：T_max=EPOCHS表示在整个训练周期内完成一个余弦周期 优化器：SGD with Momentum (momentum=0.9)，经典且有效的组合 模型保存：只保存权重(state_dict)而非整个模型，更轻量且跨平台兼容 writer.close(): 确保日志文件正确写入并释放资源 三、核心设计哲学总结 设计点 意图与价值 确定性训练 让实验可复现，科学调参 Windows兼容 num_workers=0 + if __name__ 确保跨平台稳定 可视化洞察 TensorBoard + 错误样本图，不只是看Loss/Acc，更理解模型行为 模块化 数据、模型、训练、测试分离，便于复用和扩展 防御性编程 检查错误样本数量、及时plt.close()、writer.close()，避免资源泄漏 ",
  "wordCount" : "497",
  "inLanguage": "zh",
  "datePublished": "2025-11-09T00:00:00Z",
  "dateModified": "2025-11-09T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "why"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hy4real.github.io/posts/deeplearningday1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "KEEP IT REAL",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hy4real.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hy4real.github.io/" accesskey="h" title="KEEP IT REAL (Alt + H)">KEEP IT REAL</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hy4real.github.io/" title="首页">
                    <span>首页</span>
                </a>
            </li>
            <li>
                <a href="https://hy4real.github.io/archives" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://hy4real.github.io/search" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="https://hy4real.github.io/tags" title="标签">
                    <span>标签</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hy4real.github.io/">主页</a>&nbsp;»&nbsp;<a href="https://hy4real.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      深度学习入门 Day 1
    </h1>
    <div class="post-description">
      从零开始学习深度学习
    </div>
    <div class="post-meta"><span title='2025-11-09 00:00:00 +0000 UTC'>2025年11月9日</span>&nbsp;·&nbsp;<span>why</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e4%b8%80%e6%95%b4%e4%bd%93%e6%a6%82%e8%bf%b0" aria-label="一、整体概述">一、整体概述</a></li>
                <li>
                    <a href="#%e4%ba%8c%e9%80%90%e9%83%a8%e5%88%86%e8%af%a6%e7%bb%86%e8%a7%a3%e6%9e%90" aria-label="二、逐部分详细解析">二、逐部分详细解析</a><ul>
                        
                <li>
                    <a href="#1-%e5%af%bc%e5%85%a5%e5%ba%93-lines-1-7" aria-label="1. 导入库 (Lines 1-7)">1. 导入库 (Lines 1-7)</a></li>
                <li>
                    <a href="#2-%e9%9a%8f%e6%9c%ba%e7%a7%8d%e5%ad%90%e8%ae%be%e7%bd%ae-lines-9-16" aria-label="2. 随机种子设置 (Lines 9-16)">2. 随机种子设置 (Lines 9-16)</a></li>
                <li>
                    <a href="#3-%e8%b6%85%e5%8f%82%e6%95%b0%e9%85%8d%e7%bd%ae-lines-18-21" aria-label="3. 超参数配置 (Lines 18-21)">3. 超参数配置 (Lines 18-21)</a></li>
                <li>
                    <a href="#4-%e6%95%b0%e6%8d%ae%e5%8a%a0%e8%bd%bd%e4%b8%8e%e9%a2%84%e5%a4%84%e7%90%86-lines-23-35" aria-label="4. 数据加载与预处理 (Lines 23-35)">4. 数据加载与预处理 (Lines 23-35)</a></li>
                <li>
                    <a href="#5-%e6%a8%a1%e5%9e%8b%e5%ae%9a%e4%b9%89-lines-37-48" aria-label="5. 模型定义 (Lines 37-48)">5. 模型定义 (Lines 37-48)</a></li>
                <li>
                    <a href="#6-%e8%ae%ad%e7%bb%83%e5%87%bd%e6%95%b0-lines-50-61" aria-label="6. 训练函数 (Lines 50-61)">6. 训练函数 (Lines 50-61)</a></li>
                <li>
                    <a href="#7-%e6%b5%8b%e8%af%95%e5%87%bd%e6%95%b0-lines-63-98" aria-label="7. 测试函数 (Lines 63-98)">7. 测试函数 (Lines 63-98)</a></li>
                <li>
                    <a href="#8-%e4%b8%bb%e7%a8%8b%e5%ba%8f%e4%bf%9d%e6%8a%a4%e5%a3%b3-lines-100-110" aria-label="8. 主程序保护壳 (Lines 100-110)">8. 主程序保护壳 (Lines 100-110)</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b8%89%e6%a0%b8%e5%bf%83%e8%ae%be%e8%ae%a1%e5%93%b2%e5%ad%a6%e6%80%bb%e7%bb%93" aria-label="三、核心设计哲学总结">三、核心设计哲学总结</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><hr>
<h2 id="一整体概述">一、整体概述<a hidden class="anchor" aria-hidden="true" href="#一整体概述">#</a></h2>
<p>这是一个<strong>完整的MNIST手写数字分类项目</strong>，使用PyTorch构建了一个小型卷积神经网络(CNN)。代码实现了数据加载、模型训练、测试评估、可视化错误样本和日志记录的全流程，非常适合作为深度学习入门范例。</p>
<hr>
<h2 id="二逐部分详细解析">二、逐部分详细解析<a hidden class="anchor" aria-hidden="true" href="#二逐部分详细解析">#</a></h2>
<h3 id="1-导入库-lines-1-7"><strong>1. 导入库 (Lines 1-7)</strong><a hidden class="anchor" aria-hidden="true" href="#1-导入库-lines-1-7">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">torchvision</span><span class="o">,</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span></code></pre></div><p><strong>功能</strong>：导入所有必需的工具库。</p>
<p><strong>设计意图</strong>：</p>
<ul>
<li><code>torch</code> &amp; <code>torchvision</code>: PyTorch核心框架和计算机视觉工具</li>
<li><code>time, os</code>: 基础系统功能（虽然代码中没直接用，但为扩展预留）</li>
<li><code>SummaryWriter</code>: 连接TensorBoard，实时可视化训练曲线</li>
<li><code>random, numpy</code>: 用于设置随机种子，保证结果可复现</li>
<li><code>matplotlib</code>: 绘制错误样本图，直观观察模型弱点</li>
</ul>
<hr>
<h3 id="2-随机种子设置-lines-9-16"><strong>2. 随机种子设置 (Lines 9-16)</strong><a hidden class="anchor" aria-hidden="true" href="#2-随机种子设置-lines-9-16">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
</span></span><span class="line"><span class="cl"><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>          <span class="c1"># CPU 权重</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>     <span class="c1"># GPU 权重</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="c1"># 多 GPU</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>   <span class="c1"># 卷积确定</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda&#34;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Using&#34;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>功能</strong>：<strong>强制所有随机性来源产生确定性结果</strong>，并自动选择运算设备。</p>
<p><strong>意图详解</strong>：</p>
<ul>
<li><strong>可复现性</strong>：深度学习实验依赖大量随机初始化，不设置种子的话，每次运行结果都不同，无法对比调参效果</li>
<li><strong>多层保险</strong>：分别设置Python、<code>numpy</code>、PyTorch CPU/GPU的随机种子，确保无死角</li>
<li><strong>cuDNN设置</strong>：
<ul>
<li><code>deterministic = True</code>: 牺牲一点速度，确保卷积等操作的算法是确定的</li>
<li><code>benchmark = False</code>: 禁止自动选择最优算法，避免非确定性</li>
</ul>
</li>
<li><strong>设备选择</strong>：自动检测GPU，有则用GPU加速，无则 fallback 到CPU，提升代码兼容性</li>
</ul>
<hr>
<h3 id="3-超参数配置-lines-18-21"><strong>3. 超参数配置 (Lines 18-21)</strong><a hidden class="anchor" aria-hidden="true" href="#3-超参数配置-lines-18-21">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
</span></span><span class="line"><span class="cl"><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">5</span>
</span></span><span class="line"><span class="cl"><span class="n">LR</span> <span class="o">=</span> <span class="mf">0.1</span>
</span></span></code></pre></div><p><strong>功能</strong>：集中管理训练参数。</p>
<p>在这个参数配置下，准确率达到了99.05%。</p>
<hr>
<h3 id="4-数据加载与预处理-lines-23-35"><strong>4. 数据加载与预处理 (Lines 23-35)</strong><a hidden class="anchor" aria-hidden="true" href="#4-数据加载与预处理-lines-23-35">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">                         <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))])</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ds</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">tf</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_ds</span>  <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">tf</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># FIX-1: num_workers=0 禁用多进程</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ld</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">test_ld</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_ds</span><span class="p">,</span>  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>功能</strong>：下载数据集，转换格式，封装成可迭代的数据加载器。</p>
<p><strong>逐行拆解</strong>：</p>
<ul>
<li><strong><code>transforms.ToTensor()</code></strong>: 将PIL图片(0-255)转为PyTorch张量(0.0-1.0)，并调整维度为[C, H, W]</li>
<li><strong><code>transforms.Normalize((0.1307,), (0.3081,))</code></strong>: <strong>关键步骤</strong>，对数据进行标准化
<ul>
<li><code>0.1307</code> 是MNIST训练集的<strong>均值</strong>，<code>0.3081</code> 是<strong>标准差</strong></li>
<li>意图：让数据分布接近标准正态分布，加速训练收敛，提升稳定性</li>
<li>为什么是单值？因为MNIST是灰度图，单通道；彩色图会是3个值如<code>(0.5,0.5,0.5)</code></li>
</ul>
</li>
<li><strong><code>datasets.MNIST(...)</code></strong>: 自动从网络下载数据集到<code>./data</code>文件夹</li>
<li><strong><code>DataLoader</code></strong>  :</li>
<li><code>shuffle=True</code>: 训练集打乱顺序，避免模型学到顺序偏见</li>
<li><strong><code>num_workers=0</code></strong>  : <strong>Windows系统下的重要修复</strong>。多进程加载数据在Windows上容易因<code>fork</code>机制崩溃，设为0可确保稳定</li>
<li><code>pin_memory=True</code>: 将数据锁页在内存，加速向GPU的传输</li>
</ul>
<hr>
<h3 id="5-模型定义-lines-37-48"><strong>5. 模型定义 (Lines 37-48)</strong><a hidden class="anchor" aria-hidden="true" href="#5-模型定义-lines-37-48">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span></code></pre></div><p><strong>功能</strong>：定义一个简洁高效的CNN架构。</p>
<p><strong>结构解析</strong>：</p>
<ul>
<li><strong><code>self.features</code></strong>  : 特征提取层</li>
<li><code>Conv2d(1,32,3,padding=1)</code>: 输入1通道(灰度)，输出32通道，3x3卷积，padding=1保持尺寸不变</li>
<li><code>MaxPool2d(2)</code>: 2x2最大池化，尺寸减半（28x28 → 14x14）</li>
<li><code>Conv2d(32,64,3,padding=1)</code>: 通道数升维到64</li>
<li>第二次池化后尺寸: 14x14 → 7x7</li>
<li><strong><code>self.classifier</code></strong>  : 分类头</li>
<li><code>nn.Flatten()</code>: 展平特征图，<code>64*7*7 = 3136</code>个特征</li>
<li><code>nn.Linear(3136,128)</code>: 全连接层降维到128</li>
<li><code>nn.Dropout(0.2)</code>: <strong>防止过拟合</strong>，训练时随机丢弃20%神经元</li>
<li><code>nn.Linear(128,10)</code>: 输出10个类别得分（对应数字0-9）</li>
</ul>
<p><strong>意图</strong>：这是经典的LeNet现代化变体，结构清晰，参数少（约20万），在MNIST上足够强大且训练快速。</p>
<hr>
<h3 id="6-训练函数-lines-50-61"><strong>6. 训练函数 (Lines 50-61)</strong><a hidden class="anchor" aria-hidden="true" href="#6-训练函数-lines-50-61">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_ld</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">batch_idx</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ld</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">] &#39;</span>
</span></span><span class="line"><span class="cl">                  <span class="sa">f</span><span class="s1">&#39;Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;train/loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">                              <span class="n">epoch</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ld</span><span class="p">)</span><span class="o">+</span><span class="n">batch_idx</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>功能</strong>：执行一个训练轮次，更新模型权重。</p>
<p><strong>流程详解</strong>：</p>
<ol>
<li><code>model.train()</code>: 开启训练模式（启用Dropout等）</li>
<li>遍历<code>train_ld</code>，每次取<code>BATCH_SIZE</code>个样本</li>
<li><code>x.to(device)</code>: 把数据搬到GPU/CPU</li>
<li><code>optimizer.zero_grad()</code>: <strong>清空梯度</strong>，防止梯度累积</li>
<li><code>criterion(model(x), y)</code>: 前向传播+计算交叉熵损失</li>
<li><code>loss.backward()</code>: 反向传播，计算梯度</li>
<li><code>optimizer.step()</code>: 根据梯度更新权重</li>
<li><code>scheduler.step()</code>: <strong>调整学习率</strong>（每个batch都调，注意：通常按epoch调更常见，但这样也行）</li>
<li>每100个batch打印日志，并写入TensorBoard（全局步数=epoch*总batch数+当前batch数）</li>
</ol>
<p><strong>意图</strong>：标准的训练循环，代码紧凑，注释清晰，适合教学。</p>
<hr>
<h3 id="7-测试函数-lines-63-98"><strong>7. 测试函数 (Lines 63-98)</strong><a hidden class="anchor" aria-hidden="true" href="#7-测试函数-lines-63-98">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@torch.no_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">test_ld</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">wrong_samples</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 存储错误样本的特征（x）</span>
</span></span><span class="line"><span class="cl">    <span class="n">wrong_labels</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 存储错误样本的真实标签（y）</span>
</span></span><span class="line"><span class="cl">    <span class="n">wrong_preds</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 存储错误样本的预测标签（pred）</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ... 遍历测试集 ...</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrong_samples</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">9</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">img</span> <span class="o">=</span> <span class="n">wrong_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;T:</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1"> P:</span><span class="si">{</span><span class="n">guess</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;wrong_cases.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span></code></pre></div><p><strong>功能</strong>：评估模型性能，并<strong>可视化典型错误样本</strong>。</p>
<p><strong>亮点解析</strong>：</p>
<ul>
<li><strong><code>@torch.no_grad()</code></strong>  : <strong>性能优化</strong>，禁用梯度计算，节省内存，提速30%以上</li>
<li><code>model.eval()</code>: 切换到评估模式（关闭Dropout）</li>
<li><strong>错误样本收集</strong>：这是本代码的<strong>核心价值之一</strong>
<ul>
<li>只收集9个错误样本，避免内存爆炸</li>
<li>用<code>nonzero(as_tuple=True)[0]</code>找到预测≠真实的索引</li>
<li>存储原始图像、真实标签、预测标签到CPU，便于后续绘图</li>
</ul>
</li>
<li><strong>可视化</strong>：绘制3x3网格，展示模型最容易混淆的手写数字
<ul>
<li><code>squeeze()</code>: 去除通道维度（1,28,28 → 28,28）</li>
<li><code>cmap='gray'</code>: 灰度图显示</li>
<li><code>plt.close()</code>: <strong>防止内存泄漏</strong>，释放图形资源</li>
</ul>
</li>
<li><strong>日志记录</strong>：将准确率写入TensorBoard</li>
</ul>
<p><strong>意图</strong>：不仅输出数字指标，还让开发者<strong>直观理解模型弱点</strong>（比如是7被认成9，还是3被认成8），指导后续改进方向。</p>
<hr>
<h3 id="8-主程序保护壳-lines-100-110"><strong>8. 主程序保护壳 (Lines 100-110)</strong><a hidden class="anchor" aria-hidden="true" href="#8-主程序保护壳-lines-100-110">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingLR</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;runs&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">train</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">test</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">test_ld</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;mnist_cnn.pt&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span></code></pre></div><p><strong>功能</strong>：组织训练流程，保存结果。</p>
<p><strong>关键点</strong>：</p>
<ul>
<li><strong><code>if __name__ == '__main__'</code></strong>  : <strong>Windows多进程必备</strong>。没有这个，在Windows上运行会报错或产生僵尸进程</li>
<li><strong>学习率调度器</strong>：<code>CosineAnnealingLR</code>实现<strong>余弦退火</strong>
<ul>
<li>学习率从初始值平滑下降到接近0，像cos曲线</li>
<li>意图：前期快速探索，后期精细调整， often 比固定学习率效果好</li>
<li>注意：<code>T_max=EPOCHS</code>表示在整个训练周期内完成一个余弦周期</li>
</ul>
</li>
<li><strong>优化器</strong>：SGD with Momentum (<code>momentum=0.9</code>)，经典且有效的组合</li>
<li><strong>模型保存</strong>：只保存权重(<code>state_dict</code>)而非整个模型，更轻量且跨平台兼容</li>
<li><strong>writer.close()</strong>: 确保日志文件正确写入并释放资源</li>
</ul>
<hr>
<h2 id="三核心设计哲学总结">三、核心设计哲学总结<a hidden class="anchor" aria-hidden="true" href="#三核心设计哲学总结">#</a></h2>
<table>
  <thead>
      <tr>
          <th>设计点</th>
          <th>意图与价值</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>确定性训练</strong></td>
          <td>让实验可复现，科学调参</td>
      </tr>
      <tr>
          <td><strong>Windows兼容</strong></td>
          <td><code>num_workers=0</code> + <code>if __name__</code> 确保跨平台稳定</td>
      </tr>
      <tr>
          <td><strong>可视化洞察</strong></td>
          <td>TensorBoard + 错误样本图，不只是看Loss/Acc，更理解模型行为</td>
      </tr>
      <tr>
          <td><strong>模块化</strong></td>
          <td>数据、模型、训练、测试分离，便于复用和扩展</td>
      </tr>
      <tr>
          <td><strong>防御性编程</strong></td>
          <td>检查错误样本数量、及时<code>plt.close()</code>、<code>writer.close()</code>，避免资源泄漏</td>
      </tr>
  </tbody>
</table>
<hr>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://hy4real.github.io/tags/deeplearning/">DeepLearning</a></li>
      <li><a href="https://hy4real.github.io/tags/python/">Python</a></li>
      <li><a href="https://hy4real.github.io/tags/cnn/">CNN</a></li>
      <li><a href="https://hy4real.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://hy4real.github.io/posts/deeplearningday2/">
    <span class="title">« 上一页</span>
    <br>
    <span>深度学习入门 Day 2</span>
  </a>
  <a class="next" href="https://hy4real.github.io/posts/gradthoughts/">
    <span class="title">下一页 »</span>
    <br>
    <span>没有察觉，竟已走远</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 1 on x"
            href="https://x.com/intent/tweet/?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%201&amp;url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f&amp;hashtags=DeepLearning%2cPython%2cCNN%2c%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 1 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f&amp;title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%201&amp;summary=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%201&amp;source=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 1 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f&title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%201">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 1 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 1 on whatsapp"
            href="https://api.whatsapp.com/send?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%201%20-%20https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 1 on telegram"
            href="https://telegram.me/share/url?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%201&amp;url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 1 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%201&u=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday1%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://hy4real.github.io/">KEEP IT REAL</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '复制';

        function copyingDone() {
            copybutton.innerHTML = '已复制！';
            setTimeout(() => {
                copybutton.innerHTML = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
