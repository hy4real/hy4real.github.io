<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>深度学习入门 Day 2 | KEEP IT REAL</title>
<meta name="keywords" content="DeepLearning, Python, CNN, 深度学习">
<meta name="description" content="从零开始学习深度学习">
<meta name="author" content="why">
<link rel="canonical" href="https://hy4real.github.io/posts/deeplearningday2/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css" integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn&#43;yY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://hy4real.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hy4real.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hy4real.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hy4real.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://hy4real.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://hy4real.github.io/posts/deeplearningday2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://hy4real.github.io/posts/deeplearningday2/">
  <meta property="og:site_name" content="KEEP IT REAL">
  <meta property="og:title" content="深度学习入门 Day 2">
  <meta property="og:description" content="从零开始学习深度学习">
  <meta property="og:locale" content="zh">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-11-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-11-10T00:00:00+00:00">
    <meta property="article:tag" content="DeepLearning">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="CNN">
    <meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习入门 Day 2">
<meta name="twitter:description" content="从零开始学习深度学习">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://hy4real.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "深度学习入门 Day 2",
      "item": "https://hy4real.github.io/posts/deeplearningday2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "深度学习入门 Day 2",
  "name": "深度学习入门 Day 2",
  "description": "从零开始学习深度学习",
  "keywords": [
    "DeepLearning", "Python", "CNN", "深度学习"
  ],
  "articleBody": "相较于 Day 1，mnist_cnn.py 做了两个版本的优化。\n第一版本 第一版本保持了原始代码的简洁性，仅将学习率调度从batch级别修正为epoch级别。\n优化后的精简代码 def train(epoch, model, criterion, optimizer, writer): # ... [原始代码：循环前向/反向/优化] ... # ❌ 移除了 scheduler.step() # 核心修改1 if batch_idx % 100 == 0: # ... [日志记录代码] ... # ... [train函数结束] ... # main 循环部分： for ep in range(1, EPOCHS+1): # ... [train/test调用] ... # ✅ 在epoch结束后调度学习率 # 核心修改2 scheduler.step() # ... [记录学习率 \u0026 打印] ... 在这个参数和修改下，测试准确率达到了99.34%。\n位置 原始代码 优化后代码 意图 train()函数内 scheduler.step()在batch循环中 完全移除 避免学习率下降过快，每个batch都调整会导致训练不稳定 主循环内 无 新增scheduler.step()在epoch末尾 学习率按epoch周期平滑衰减，符合CosineAnnealingLR的设计思想 为何保持其他部分不变？ 无argparse：保持原始硬编码风格，代码更简洁，适合快速实验 无验证集：简化流程，直接5 epoch后看测试集结果（MNIST简单，过拟合风险低） 无数据增强：保持原始数据分布，最直接观察模型对干净数据的拟合能力 总结：此版本改动最小（仅2行代码移动），却修正了最关键的调度逻辑问题，是 性价比最高的优化 。\n第二版本 这个版本的测试准确率提升至99.44%。\n1. 数据增强：泛化能力的基石 # 原代码：仅标准化 train_tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize(...)]) # 改进后： train_tf = transforms.Compose([ transforms.ToTensor(), transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)), # 核心增强 transforms.Normalize((0.1307,), (0.3081,)) ]) 意图与效果：\ndegrees=10：随机旋转±10度，模拟手写笔迹倾斜 translate=(0.1, 0.1)：随机平移10%，模拟数字在画布中的位置偏移 效果：训练集有效扩大10倍，模型被迫学习旋转/平移不变性，测试时对未见过的手写风格更鲁棒 2. 验证集拆分：早停机制的前提 # 原代码：训练集 = 全量60000张 train_ds = datasets.MNIST(...) # 改进后： val_size = int(len(full_train_ds) * 0.2) # 划出20%验证集 train_size = len(full_train_ds) - val_size train_ds, val_ds = random_split(full_train_ds, [train_size, val_size], generator=torch.Generator().manual_seed(args.seed)) 意图与价值：\n验证集作用：作为\"模拟考试\"，真实反映模型泛化能力 关键细节：使用generator保证拆分可复现，实验结果稳定 早停逻辑：\nfor ep in range(1, args.epochs + 1): train(...) # 训练 val_acc, _ = evaluate(...) # 验证 if val_acc \u003e best_val_acc: # 验证准确率提升？ best_val_acc = val_acc patience_counter = 0 torch.save(model.state_dict(), 'mnist_cnn_best.pt') # 保存最优 else: patience_counter += 1 if patience_counter \u003e= 3: # 连续3轮无提升则停 break 为何能提升准确率：\n防止过拟合：避免模型在训练集上\"死记硬背\"，在验证集下降时及时停止 模型选择：最终测试的是验证集上最优的模型，而非最后一个epoch的模型 3. 权重衰减（L2正则化） # 原代码： optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) # 改进后： optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4) 意图：\nweight_decay=1e-4：惩罚大权重，迫使模型学习更简单的决策边界 为何能提升准确率：\n数据增强+早停已降低过拟合风险，L2正则化进一步约束模型复杂度 在MNIST这种小数据集上效果更明显 协同效应：与Dropout(0.2)形成双重正则化 4. 性能优化细节 x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True) non_blocking=True：允许CPU-GPU数据传输与计算重叠，潜在提速10-15% 虽然不影响准确率，但能更快完成实验迭代 附上第二版完整代码 import torch, torchvision, time, os from torch import nn from torch.utils.data import DataLoader, random_split from torchvision import datasets, transforms from torch.utils.tensorboard import SummaryWriter import random, numpy as np import matplotlib.pyplot as plt import argparse from torch.optim.lr_scheduler import CosineAnnealingLR # ========== 1. 命令行参数配置 ========== 默认参数下跑了 99.44% def parse_args(): parser = argparse.ArgumentParser(description='MNIST CNN with improvements') parser.add_argument('--batch-size', type=int, default=128, help='批大小') parser.add_argument('--epochs', type=int, default=10, help='训练轮数') parser.add_argument('--lr', type=float, default=0.1, help='初始学习率') parser.add_argument('--seed', type=int, default=42, help='随机种子') parser.add_argument('--patience', type=int, default=3, help='早停耐心轮数') parser.add_argument('--val-split', type=float, default=0.2, help='验证集比例') parser.add_argument('--data-dir', type=str, default='data', help='数据存储目录') parser.add_argument('--log-dir', type=str, default='runs', help='TensorBoard日志目录') parser.add_argument('--save-path', type=str, default='mnist_cnn_best.pt', help='最佳模型保存路径') return parser.parse_args() # ========== 2. 可复现性设置 ========== def set_seed(seed): random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed_all(seed) torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False # ========== 3. 数据增强与加载 ========== def get_datasets(data_dir, val_split): # 训练集增强：轻微旋转、平移，提升泛化能力 train_tf = transforms.Compose([ transforms.ToTensor(), transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)), # 核心增强 transforms.Normalize((0.1307,), (0.3081,)) ]) # 验证/测试集：仅标准化，不增强 val_test_tf = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]) # 下载完整训练集 full_train_ds = datasets.MNIST(root=data_dir, train=True, download=True, transform=train_tf) # 拆分训练集与验证集 val_size = int(len(full_train_ds) * val_split) train_size = len(full_train_ds) - val_size train_ds, val_ds = random_split(full_train_ds, [train_size, val_size], generator=torch.Generator().manual_seed(args.seed)) # 测试集 test_ds = datasets.MNIST(root=data_dir, train=False, download=True, transform=val_test_tf) return train_ds, val_ds, test_ds # ========== 4. 模型定义 ========== class Net(nn.Module): def __init__(self): super().__init__() self.features = nn.Sequential( nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2) ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(64 * 7 * 7, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 10) ) def forward(self, x): return self.classifier(self.features(x)) # ========== 5. 训练函数（移除scheduler.step） ========== def train(epoch, model, criterion, optimizer, train_ld, writer, device): model.train() total_loss = 0 for batch_idx, (x, y) in enumerate(train_ld): x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True) optimizer.zero_grad() loss = criterion(model(x), y) loss.backward() optimizer.step() total_loss += loss.item() if batch_idx % 100 == 0: print(f'Epoch {epoch} [{batch_idx * len(x)}/{len(train_ld.dataset)}] ' f'Loss: {loss.item():.4f}') # 记录平均训练损失 writer.add_scalar('train/loss', total_loss / len(train_ld), epoch) # ========== 6. 验证/测试函数 ========== @torch.no_grad() def evaluate(epoch, model, criterion, data_ld, writer, device, split_name='val'): model.eval() correct, total, total_loss = 0, 0, 0 for x, y in data_ld: x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True) out = model(x) loss = criterion(out, y) total_loss += loss.item() _, pred = torch.max(out, 1) total += y.size(0) correct += (pred == y).sum().item() acc = 100. * correct / total avg_loss = total_loss / len(data_ld) print(f'Epoch {epoch} {split_name.capitalize()} Accuracy: {acc:.2f}% | Loss: {avg_loss:.4f}') writer.add_scalar(f'{split_name}/accuracy', acc, epoch) writer.add_scalar(f'{split_name}/loss', avg_loss, epoch) return acc, avg_loss # ========== 7. 错误样本可视化（整合到evaluate） ========== # 在evaluate函数内部，返回acc后追加： # ... [前面代码不变] ... # 收集错误样本（仅测试时） wrong_samples, wrong_labels, wrong_preds = [], [], [] if split_name == 'test': for x, y in data_ld: x, y = x.to(device), y.to(device) out = model(x) _, pred = torch.max(out, 1) wrong_idx = (pred != y).nonzero(as_tuple=True)[0] if len(wrong_samples) \u003c 9 and len(wrong_idx) \u003e 0: need = 9 - len(wrong_samples) take = min(need, len(wrong_idx)) wrong_samples.extend(x[wrong_idx[:take]].cpu()) wrong_labels.extend(y[wrong_idx[:take]].cpu().numpy()) wrong_preds.extend(pred[wrong_idx[:take]].cpu().numpy()) if len(wrong_samples) \u003e= 9: break if len(wrong_samples) \u003e= 9: plt.figure(figsize=(9, 9)) for i in range(9): img = wrong_samples[i].squeeze() plt.subplot(3, 3, i + 1) plt.imshow(img, cmap='gray') plt.title(f'T:{wrong_labels[i]} P:{wrong_preds[i]}') plt.axis('off') plt.tight_layout() plt.savefig('wrong_cases.png', dpi=120) plt.close() print(\"已保存错误样本图：wrong_cases.png\") return acc # ========== 8. 主函数 ========== def main(args): # 设置随机种子 set_seed(args.seed) # 设备 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") print(f\"Using {device} | PyTorch {torch.__version__}\") # 数据加载 train_ds, val_ds, test_ds = get_datasets(args.data_dir, args.val_split) train_ld = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True) val_ld = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0, pin_memory=True) test_ld = DataLoader(test_ds, batch_size=args.batch_size, shuffle=False, num_workers=0, pin_memory=True) # 模型、损失、优化器、调度器 model = Net().to(device) criterion = nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4) scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs) # TensorBoard writer = SummaryWriter(args.log_dir) # ========== 9. 早停逻辑 ========== best_val_acc = 0.0 patience_counter = 0 for ep in range(1, args.epochs + 1): print(f\"\\n{'=' * 50}\\nEpoch {ep}/{args.epochs}\\n{'=' * 50}\") # 训练 train(ep, model, criterion, optimizer, train_ld, writer, device) # 验证（每个epoch后） val_acc, val_loss = evaluate(ep, model, criterion, val_ld, writer, device, 'val') # 学习率调度（移到epoch级别） scheduler.step() current_lr = optimizer.param_groups[0]['lr'] writer.add_scalar('train/lr', current_lr, ep) print(f'Current LR: {current_lr:.6f}') # 早停检查 if val_acc \u003e best_val_acc: best_val_acc = val_acc patience_counter = 0 torch.save(model.state_dict(), args.save_path) # 保存最佳模型 print(f'✓ 验证准确率提升，模型已保存至 {args.save_path}') else: patience_counter += 1 print(f'✗ 验证准确率未提升，耐心计数: {patience_counter}/{args.patience}') if patience_counter \u003e= args.patience: print(f\"早停触发！最佳验证准确率: {best_val_acc:.2f}%\") break # ========== 10. 最终测试 ========== print(\"\\n加载最佳模型进行最终测试...\") model.load_state_dict(torch.load(args.save_path, map_location=device, weights_only=True)) test_acc, _ = evaluate(ep, model, criterion, test_ld, writer, device, 'test') print(f\"最终测试准确率: {test_acc:.2f}%\") writer.close() print(\"\\n训练完成！\") # ========== 入口 ========== if __name__ == '__main__': args = parse_args() print(\"配置参数:\", vars(args)) main(args) ",
  "wordCount" : "902",
  "inLanguage": "zh",
  "datePublished": "2025-11-10T00:00:00Z",
  "dateModified": "2025-11-10T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "why"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hy4real.github.io/posts/deeplearningday2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "KEEP IT REAL",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hy4real.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hy4real.github.io/" accesskey="h" title="KEEP IT REAL (Alt + H)">KEEP IT REAL</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hy4real.github.io/" title="首页">
                    <span>首页</span>
                </a>
            </li>
            <li>
                <a href="https://hy4real.github.io/archives" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://hy4real.github.io/search" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="https://hy4real.github.io/tags" title="标签">
                    <span>标签</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hy4real.github.io/">主页</a>&nbsp;»&nbsp;<a href="https://hy4real.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      深度学习入门 Day 2
    </h1>
    <div class="post-description">
      从零开始学习深度学习
    </div>
    <div class="post-meta"><span title='2025-11-10 00:00:00 +0000 UTC'>2025年11月10日</span>&nbsp;·&nbsp;<span>why</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e7%ac%ac%e4%b8%80%e7%89%88%e6%9c%ac" aria-label="第一版本">第一版本</a><ul>
                        
                <li>
                    <a href="#%e4%bc%98%e5%8c%96%e5%90%8e%e7%9a%84%e7%b2%be%e7%ae%80%e4%bb%a3%e7%a0%81" aria-label="优化后的精简代码">优化后的精简代码</a></li>
                <li>
                    <a href="#%e4%b8%ba%e4%bd%95%e4%bf%9d%e6%8c%81%e5%85%b6%e4%bb%96%e9%83%a8%e5%88%86%e4%b8%8d%e5%8f%98" aria-label="为何保持其他部分不变？">为何保持其他部分不变？</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e7%89%88%e6%9c%ac" aria-label="第二版本">第二版本</a><ul>
                        
                <li>
                    <a href="#1-%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba%e6%b3%9b%e5%8c%96%e8%83%bd%e5%8a%9b%e7%9a%84%e5%9f%ba%e7%9f%b3" aria-label="1. 数据增强：泛化能力的基石">1. 数据增强：泛化能力的基石</a></li>
                <li>
                    <a href="#2-%e9%aa%8c%e8%af%81%e9%9b%86%e6%8b%86%e5%88%86%e6%97%a9%e5%81%9c%e6%9c%ba%e5%88%b6%e7%9a%84%e5%89%8d%e6%8f%90" aria-label="2. 验证集拆分：早停机制的前提">2. 验证集拆分：早停机制的前提</a></li>
                <li>
                    <a href="#3-%e6%9d%83%e9%87%8d%e8%a1%b0%e5%87%8fl2%e6%ad%a3%e5%88%99%e5%8c%96" aria-label="3. 权重衰减（L2正则化）">3. 权重衰减（L2正则化）</a></li>
                <li>
                    <a href="#4-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e7%bb%86%e8%8a%82" aria-label="4. 性能优化细节">4. 性能优化细节</a></li>
                <li>
                    <a href="#%e9%99%84%e4%b8%8a%e7%ac%ac%e4%ba%8c%e7%89%88%e5%ae%8c%e6%95%b4%e4%bb%a3%e7%a0%81" aria-label="附上第二版完整代码">附上第二版完整代码</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>相较于 Day 1，mnist_cnn.py 做了两个版本的优化。</p>
<hr>
<h2 id="第一版本">第一版本<a hidden class="anchor" aria-hidden="true" href="#第一版本">#</a></h2>
<p>第一版本保持了原始代码的简洁性，仅将学习率调度从<code>batch</code>级别修正为<code>epoch</code>级别。</p>
<h3 id="优化后的精简代码"><strong>优化后的精简代码</strong><a hidden class="anchor" aria-hidden="true" href="#优化后的精简代码">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">writer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ... [原始代码：循环前向/反向/优化] ...</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># ❌ 移除了 scheduler.step()  # 核心修改1</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ... [日志记录代码] ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ... [train函数结束] ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># main 循环部分：</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ... [train/test调用] ...</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># ✅ 在epoch结束后调度学习率  # 核心修改2</span>
</span></span><span class="line"><span class="cl">    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ... [记录学习率 &amp; 打印] ...</span>
</span></span></code></pre></div><p>在这个参数和修改下，测试准确率达到了99.34%。</p>
<table>
  <thead>
      <tr>
          <th>位置</th>
          <th>原始代码</th>
          <th>优化后代码</th>
          <th>意图</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>train()函数内</strong></td>
          <td><code>scheduler.step()</code>在batch循环中</td>
          <td><strong>完全移除</strong></td>
          <td>避免学习率下降过快，每个batch都调整会导致训练不稳定</td>
      </tr>
      <tr>
          <td><strong>主循环内</strong></td>
          <td>无</td>
          <td><strong>新增</strong><code>scheduler.step()</code>在epoch末尾</td>
          <td>学习率按epoch周期平滑衰减，符合CosineAnnealingLR的设计思想</td>
      </tr>
  </tbody>
</table>
<hr>
<h3 id="为何保持其他部分不变"><strong>为何保持其他部分不变？</strong><a hidden class="anchor" aria-hidden="true" href="#为何保持其他部分不变">#</a></h3>
<ol>
<li><strong>无argparse</strong>：保持原始硬编码风格，代码更简洁，适合快速实验</li>
<li><strong>无验证集</strong>：简化流程，直接5 epoch后看测试集结果（MNIST简单，过拟合风险低）</li>
<li><strong>无数据增强</strong>：保持原始数据分布，最直接观察模型对干净数据的拟合能力</li>
</ol>
<p><strong>总结</strong>：此版本<strong>改动最小（仅2行代码移动）</strong>，却修正了最关键的调度逻辑问题，是 <strong>性价比最高的优化</strong> 。</p>
<h2 id="第二版本">第二版本<a hidden class="anchor" aria-hidden="true" href="#第二版本">#</a></h2>
<p>这个版本的测试准确率提升至99.44%。</p>
<hr>
<h3 id="1-数据增强泛化能力的基石"><strong>1. 数据增强：泛化能力的基石</strong><a hidden class="anchor" aria-hidden="true" href="#1-数据增强泛化能力的基石">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 原代码：仅标准化</span>
</span></span><span class="line"><span class="cl"><span class="n">train_tf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="o">...</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 改进后：</span>
</span></span><span class="line"><span class="cl"><span class="n">train_tf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomAffine</span><span class="p">(</span><span class="n">degrees</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">translate</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>  <span class="c1"># 核心增强</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span></code></pre></div><p><strong>意图与效果</strong>：</p>
<ul>
<li><code>degrees=10</code>：随机旋转±10度，模拟手写笔迹倾斜</li>
<li><code>translate=(0.1, 0.1)</code>：随机平移10%，模拟数字在画布中的位置偏移</li>
<li><strong>效果</strong>：训练集有效扩大10倍，模型被迫学习<strong>旋转/平移不变性</strong>，测试时对未见过的手写风格更鲁棒</li>
</ul>
<hr>
<h3 id="2-验证集拆分早停机制的前提"><strong>2. 验证集拆分：早停机制的前提</strong><a hidden class="anchor" aria-hidden="true" href="#2-验证集拆分早停机制的前提">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 原代码：训练集 = 全量60000张</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ds</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 改进后：</span>
</span></span><span class="line"><span class="cl"><span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">full_train_ds</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>  <span class="c1"># 划出20%验证集</span>
</span></span><span class="line"><span class="cl"><span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_train_ds</span><span class="p">)</span> <span class="o">-</span> <span class="n">val_size</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">full_train_ds</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">))</span>
</span></span></code></pre></div><p><strong>意图与价值</strong>：</p>
<ul>
<li><strong>验证集作用</strong>：作为&quot;模拟考试&quot;，真实反映模型泛化能力</li>
<li><strong>关键细节</strong>：使用<code>generator</code>保证拆分可复现，实验结果稳定</li>
</ul>
<p><strong>早停逻辑</strong>：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># 训练</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_acc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># 验证</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">best_val_acc</span><span class="p">:</span>  <span class="c1"># 验证准确率提升？</span>
</span></span><span class="line"><span class="cl">        <span class="n">best_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span>
</span></span><span class="line"><span class="cl">        <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;mnist_cnn_best.pt&#39;</span><span class="p">)</span>  <span class="c1"># 保存最优</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># 连续3轮无提升则停</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span>
</span></span></code></pre></div><p><strong>为何能提升准确率</strong>：</p>
<ul>
<li><strong>防止过拟合</strong>：避免模型在训练集上&quot;死记硬背&quot;，在验证集下降时及时停止</li>
<li><strong>模型选择</strong>：最终测试的是<strong>验证集上最优的模型</strong>，而非最后一个epoch的模型</li>
</ul>
<hr>
<h3 id="3-权重衰减l2正则化"><strong>3. 权重衰减（L2正则化）</strong><a hidden class="anchor" aria-hidden="true" href="#3-权重衰减l2正则化">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 原代码：</span>
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 改进后：</span>
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>意图</strong>：</p>
<ul>
<li><code>weight_decay=1e-4</code>：惩罚大权重，迫使模型学习更简单的决策边界</li>
</ul>
<p><strong>为何能提升准确率</strong>：</p>
<ul>
<li>数据增强+早停已降低过拟合风险，L2正则化进一步<strong>约束模型复杂度</strong></li>
<li>在MNIST这种小数据集上效果更明显</li>
<li><strong>协同效应</strong>：与Dropout(0.2)形成双重正则化</li>
</ul>
<hr>
<h3 id="4-性能优化细节"><strong>4. 性能优化细节</strong><a hidden class="anchor" aria-hidden="true" href="#4-性能优化细节">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><ul>
<li><code>non_blocking=True</code>：允许CPU-GPU数据传输与计算重叠，<strong>潜在提速10-15%</strong></li>
<li>虽然不影响准确率，但能更快完成实验迭代</li>
</ul>
<hr>
<h3 id="附上第二版完整代码"><strong>附上第二版完整代码</strong><a hidden class="anchor" aria-hidden="true" href="#附上第二版完整代码">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">torchvision</span><span class="o">,</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">argparse</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingLR</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 1. 命令行参数配置 ========== 默认参数下跑了 99.44%</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">parse_args</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;MNIST CNN with improvements&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch-size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;批大小&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--epochs&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;训练轮数&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;初始学习率&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--seed&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;随机种子&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--patience&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;早停耐心轮数&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--val-split&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;验证集比例&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--data-dir&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;数据存储目录&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--log-dir&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;runs&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;TensorBoard日志目录&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--save-path&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;mnist_cnn_best.pt&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;最佳模型保存路径&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 2. 可复现性设置 ==========</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 3. 数据增强与加载 ==========</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_datasets</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">val_split</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 训练集增强：轻微旋转、平移，提升泛化能力</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_tf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomAffine</span><span class="p">(</span><span class="n">degrees</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">translate</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>  <span class="c1"># 核心增强</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 验证/测试集：仅标准化，不增强</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_test_tf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 下载完整训练集</span>
</span></span><span class="line"><span class="cl">    <span class="n">full_train_ds</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">train_tf</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 拆分训练集与验证集</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">full_train_ds</span><span class="p">)</span> <span class="o">*</span> <span class="n">val_split</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_train_ds</span><span class="p">)</span> <span class="o">-</span> <span class="n">val_size</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">full_train_ds</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 测试集</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_ds</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">val_test_tf</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">,</span> <span class="n">test_ds</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 4. 模型定义 ==========</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 5. 训练函数（移除scheduler.step） ==========</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_ld</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_ld</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ld</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">] &#39;</span>
</span></span><span class="line"><span class="cl">                  <span class="sa">f</span><span class="s1">&#39;Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 记录平均训练损失</span>
</span></span><span class="line"><span class="cl">    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;train/loss&#39;</span><span class="p">,</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_ld</span><span class="p">),</span> <span class="n">epoch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 6. 验证/测试函数 ==========</span>
</span></span><span class="line"><span class="cl"><span class="nd">@torch.no_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">data_ld</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">split_name</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_ld</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">acc</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</span></span><span class="line"><span class="cl">    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_ld</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">split_name</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span><span class="si">}</span><span class="s1"> Accuracy: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">% | Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">split_name</span><span class="si">}</span><span class="s1">/accuracy&#39;</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">split_name</span><span class="si">}</span><span class="s1">/loss&#39;</span><span class="p">,</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">acc</span><span class="p">,</span> <span class="n">avg_loss</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># ========== 7. 错误样本可视化（整合到evaluate） ==========</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 在evaluate函数内部，返回acc后追加：</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ... [前面代码不变] ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 收集错误样本（仅测试时）</span>
</span></span><span class="line"><span class="cl">    <span class="n">wrong_samples</span><span class="p">,</span> <span class="n">wrong_labels</span><span class="p">,</span> <span class="n">wrong_preds</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">split_name</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_ld</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wrong_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">!=</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrong_samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">9</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrong_idx</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">need</span> <span class="o">=</span> <span class="mi">9</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrong_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">take</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">need</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrong_idx</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                <span class="n">wrong_samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">wrong_idx</span><span class="p">[:</span><span class="n">take</span><span class="p">]]</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">                <span class="n">wrong_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">wrong_idx</span><span class="p">[:</span><span class="n">take</span><span class="p">]]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">                <span class="n">wrong_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">wrong_idx</span><span class="p">[:</span><span class="n">take</span><span class="p">]]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrong_samples</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">9</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">break</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrong_samples</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">9</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">img</span> <span class="o">=</span> <span class="n">wrong_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;T:</span><span class="si">{</span><span class="n">wrong_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1"> P:</span><span class="si">{</span><span class="n">wrong_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;wrong_cases.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;已保存错误样本图：wrong_cases.png&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">acc</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 8. 主函数 ==========</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 设置随机种子</span>
</span></span><span class="line"><span class="cl">    <span class="n">set_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 设备</span>
</span></span><span class="line"><span class="cl">    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda&#34;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2"> | PyTorch </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 数据加载</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">,</span> <span class="n">test_ds</span> <span class="o">=</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">val_split</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_ld</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                          <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_ld</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_ld</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 模型、损失、优化器、调度器</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># TensorBoard</span>
</span></span><span class="line"><span class="cl">    <span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># ========== 9. 早停逻辑 ==========</span>
</span></span><span class="line"><span class="cl">    <span class="n">best_val_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">    <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">50</span><span class="si">}</span><span class="se">\n</span><span class="s2">Epoch </span><span class="si">{</span><span class="n">ep</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">50</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 训练</span>
</span></span><span class="line"><span class="cl">        <span class="n">train</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_ld</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 验证（每个epoch后）</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">val_ld</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 学习率调度（移到epoch级别）</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">current_lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;train/lr&#39;</span><span class="p">,</span> <span class="n">current_lr</span><span class="p">,</span> <span class="n">ep</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Current LR: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 早停检查</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">best_val_acc</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">best_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span>
</span></span><span class="line"><span class="cl">            <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="p">)</span>  <span class="c1"># 保存最佳模型</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;✓ 验证准确率提升，模型已保存至 </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;✗ 验证准确率未提升，耐心计数: </span><span class="si">{</span><span class="n">patience_counter</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">patience</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="n">args</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;早停触发！最佳验证准确率: </span><span class="si">{</span><span class="n">best_val_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">break</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># ========== 10. 最终测试 ==========</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">加载最佳模型进行最终测试...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_acc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">test_ld</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;最终测试准确率: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">训练完成！&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ========== 入口 ==========</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;配置参数:&#34;</span><span class="p">,</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://hy4real.github.io/tags/deeplearning/">DeepLearning</a></li>
      <li><a href="https://hy4real.github.io/tags/python/">Python</a></li>
      <li><a href="https://hy4real.github.io/tags/cnn/">CNN</a></li>
      <li><a href="https://hy4real.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://hy4real.github.io/posts/deeplearningday1/">
    <span class="title">下一页 »</span>
    <br>
    <span>深度学习入门 Day 1</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 2 on x"
            href="https://x.com/intent/tweet/?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%202&amp;url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f&amp;hashtags=DeepLearning%2cPython%2cCNN%2c%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 2 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f&amp;title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%202&amp;summary=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%202&amp;source=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 2 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f&title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%202">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 2 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 2 on whatsapp"
            href="https://api.whatsapp.com/send?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%202%20-%20https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 2 on telegram"
            href="https://telegram.me/share/url?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%202&amp;url=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 深度学习入门 Day 2 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%85%a5%e9%97%a8%20Day%202&u=https%3a%2f%2fhy4real.github.io%2fposts%2fdeeplearningday2%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://hy4real.github.io/">KEEP IT REAL</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '复制';

        function copyingDone() {
            copybutton.innerHTML = '已复制！';
            setTimeout(() => {
                copybutton.innerHTML = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
