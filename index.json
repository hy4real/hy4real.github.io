[{"content":"今日在进行 CIFAR-10 数据集的分类实验，使用 PyTorch 框架进行实验。 一共做了两个版本的模板，第一版的准确率是 67% 左右，第二版的准确率到了 83.43%。\n第一版 一、随机种子固定（可复现性） seed = 42 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) # ...（更多CUDA种子设置） torch.backends.cudnn.deterministic = True 作用：确保每次运行结果完全一致。\n原理：随机数生成器（数据打乱、权重初始化、Dropout等）都从固定起点开始。\n注意：benchmark=False会牺牲一点速度换取确定性。\n二、设备配置（GPU加速） device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) 作用：自动检测并使用GPU，否则用CPU。\n效果：GPU可将训练速度提升10-50倍。\n三、数据加载与预处理（核心部分） 1. 数据增强（仅训练集） transform_train = transforms.Compose([ transforms.RandomHorizontalFlip(), # 50%概率水平翻转（增强泛化） transforms.RandomCrop(32, padding=4), # 四周填充4像素后随机裁剪回32×32 transforms.ToTensor(), # 转为0-1的Tensor [C,H,W] transforms.Normalize((0.4914, 0.4822, 0.4465), # 每个通道的均值 (0.2471, 0.2435, 0.2616)) # 每个通道的标准差 ]) CIFAR-10均值/标准差：这些是数据集统计值，标准化后数据分布接近标准正态分布，加速收敛。\n2. 测试集转换（无增强） transform_test = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(...) # 必须与训练集同分布 ]) 3. DataLoader train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=0) batch_size=128：每次喂给模型128张图片 shuffle=True：训练集每轮打乱顺序 num_workers=0：数据加载进程数（0表示主进程加载，简单项目够用） 四、模型架构详解（5层CNN） 特征提取器 self.features 这里的张量格式遵循 PyTorch 的约定：[B, C, H, W]，其中：\nB : Batch Size，批量处理的图片数量；\nC : Channels，通道数（如RGB图像为3）；\nH : Height，图像高度；\nW : Width，图像宽度。\nnn.Conv2d(3, 32, 3, padding=1), # [B,3,32,32] → [B,32,32,32] nn.ReLU(), nn.MaxPool2d(2), # [B,32,32,32] → [B,32,16,16] nn.Conv2d(32, 64, 3, padding=1), # [B,32,16,16] → [B,64,16,16] nn.ReLU(), nn.Conv2d(64, 128, 3, padding=1), # [B,64,16,16] → [B,128,16,16] nn.ReLU(), nn.MaxPool2d(2), # [B,128,16,16] → [B,128,8,8] 卷积层设计：\n3×3小卷积核，padding=1保持尺寸不变 通道数递增：32→64→128（特征金字塔） 2次池化：空间尺寸32→16→8 分类器 self.classifier nn.Flatten(), # [B,128,8,8] → [B,8192] nn.Linear(128 * 8 * 8, 256), # [B,8192] → [B,256] (FC层) nn.ReLU(), nn.Dropout(0.5), # 训练时随机失活50%神经元 nn.Linear(256, 10) # [B,256] → [B,10] (输出层) 五、训练配置策略 1. 损失函数 criterion = nn.CrossEntropyLoss() 作用：结合了LogSoftmax + NLLLoss，自动处理原始输出（logits）。\n输入：模型未归一化的输出 [B,10] 和类别标签 [B]。\n2. 优化器 optimizer = optim.Adam(model.parameters(), lr=3e-4) Adam：自适应学习率，几乎无需调参，适合初学者 lr=3e-4：经验性最优学习率（对很多模型都有效） 3. 学习率调度器 scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5) 策略：每2个epoch，学习率减半。\n效果：后期精细化调整参数。\n注意：对CIFAR-10可能过于激进，10个epoch会衰减3次（最终lr=3e-4×0.5³=3.75e-5）。\n六、训练循环 train() model.train() # 关键：启用Dropout/BN训练模式 for batch_idx, (inputs, labels) in enumerate(train_loader): inputs, labels = inputs.to(device), labels.to(device) # 数据移至GPU optimizer.zero_grad() # 清空梯度（避免累积） outputs = model(inputs) # 前向传播 loss = criterion(outputs, labels) # 计算损失 loss.backward() # 反向传播计算梯度 optimizer.step() # 更新权重 if batch_idx % 100 == 0: # 每100个batch打印一次 print(f\u0026#34;Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\u0026#34;) 七、测试/验证 test() model.eval() # 关键：关闭Dropout/BN评估模式 with torch.no_grad(): # 禁用梯度计算（节省内存，加速） for inputs, labels in test_loader: inputs, labels = inputs.to(device), labels.to(device) outputs = model(inputs) _, predicted = torch.max(outputs.data, 1) # 取最大概率的类别 total += labels.size(0) correct += (predicted == labels).sum().item() 注意：代码直接用测试集作为验证集，学术上不够严谨，建议拆分出验证集。\n八、主执行流程 for epoch in range(1, 11): train(epoch) test(epoch) scheduler.step() # 每个epoch后调整学习率 训练节奏：\n共10个epoch 每个epoch：训练（打印loss）→ 测试（打印acc）→ 调整lr 九、模型特点与潜在问题 优点 ✅ 结构清晰，适合CIFAR-10入门\n✅ 数据增强合理\n✅ 使用现代优化器（Adam）\n潜在问题 ⚠️ 模型容量较小：3层卷积对CIFAR-10可能欠拟合，SOTA模型通常需要6+层\n⚠️ 无验证集：直接用测试集调参有数据泄露风险\n⚠️ num_workers=0：数据加载可能成为瓶颈（建议≥2）\n⚠️ 学习率衰减快：10个epoch可能不足以充分发挥模型潜力\n⚠️ 缺少早停：无法自动保存最优模型\n十、改进建议 增加验证集： train_set, val_set = torch.utils.data.random_split(train_set, [45000, 5000]) 保存最佳模型： best_acc = 0 if acc \u0026gt; best_acc: torch.save(model.state_dict(), \u0026#39;best_model.pth\u0026#39;) best_acc = acc 增强模型： 增加卷积层深度（如VGG-style：64-128-256-512） 添加BatchNorm层：nn.Conv2d(...), nn.BatchNorm2d(32), nn.ReLU() 一句话总结：这是一个标准的CIFAR-10入门级CNN，适合教学和快速实验，但距离SOTA还有较大优化空间。\n下附完整代码：\nimport torch import torchvision from torch import nn, optim from torch.utils.data import DataLoader from torchvision import datasets, transforms import numpy as np import random # 固定随机种子 seed = 42 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed(seed) torch.cuda.manual_seed_all(seed) torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False # 使用 GPU device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # 数据加载 transform_train = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)) ]) transform_test = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)) ]) train_set = datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform_train) test_set = datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform_test) train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=0) test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=0) # 模型定义 class CNN(nn.Module): def __init__(self): super().__init__() self.features = nn.Sequential( nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(128 * 8 * 8, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, 10) ) def forward(self, x): x = self.features(x) x = self.classifier(x) return x model = CNN().to(device) # 优化器和损失函数 criterion = nn.CrossEntropyLoss() optimizer = optim.Adam(model.parameters(), lr=3e-4) scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5) # 训练和验证 def train(epoch): model.train() for batch_idx, (inputs, labels) in enumerate(train_loader): inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() if batch_idx % 100 == 0: print(f\u0026#34;Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\u0026#34;) def test(epoch): model.eval() correct, total = 0, 0 with torch.no_grad(): for inputs, labels in test_loader: inputs, labels = inputs.to(device), labels.to(device) outputs = model(inputs) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f\u0026#34;Epoch {epoch}, Accuracy: {100 * correct / total:.2f}%\u0026#34;) for epoch in range(1, 11): train(epoch) test(epoch) scheduler.step() 第二版 这是CIFAR-10分类任务的升级版（v2）代码。我将逐部分解析，并与前一个版本（v1） 做详细对比：\n一、整体结构对比 特性 v1（基础版） v2（升级版） 改进目的 模型容量 3层卷积，通道数32-64-128 4层卷积，通道数64-128-256-256 增加非线性表达能力 全连接层 2层（256→10） 3层（512→256→10） 缓解特征压缩 Dropout 0.5（仅最后） 0.3（两层FC后） 更细粒度正则化 学习率调度 StepLR（阶梯衰减） CosineAnnealingLR（余弦退火） 平滑学习率调整 初始学习率 3e-4 1e-3 配合余弦退火更大探索空间 二、模型架构（ 最大变化 ） v2模型结构解析 self.features = nn.Sequential( nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(), nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), # 第一次池化：32×32 → 16×16 nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), # 第二次池化：16×16 → 8×8 ) 关键对比与改进 层级 v1顺序 v2顺序 设计差异分析 Layer1 Conv3→32 + ReLU + Pool Conv3→64 + ReLU（无池化） v2延迟池化，保留早期特征分辨率 Layer2 Conv32→64 + ReLU Conv64→128 + ReLU + Pool v2将池化后移，减少信息损失 Layer3 Conv64→128 + ReLU + Pool Conv128→256 + ReLU v2增加深度，提取更抽象特征 Layer4 ❌ 无 Conv256→256 + ReLU + Pool v2新增层，扩大感受野和容量 v2的优势如下：\n延迟池化：早期层保留更多空间细节，利于小目标（CIFAR-10图像仅32×32） 增加深度：4层卷积能学习更复杂的特征层次（边缘→纹理→部件→物体） 通道翻倍：后期256通道提供足够容量编码高级语义 三、分类器部分（ 正则化加强 ） self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(256 * 8 * 8, 512), # 输入节点从128*8*8=8192增加到256*8*8=16384 nn.ReLU(), nn.Dropout(0.3), # 第一个Dropout nn.Linear(512, 256), # 新增中间层 nn.ReLU(), nn.Dropout(0.3), # 第二个Dropout nn.Linear(256, 10) ) 对比总结：\n特性 v1 v2 改进意义 FC层数 2层 3层 缓解维度坍缩过快 Dropout次数 1次（仅最后） 2次 双重正则，防止中间层过拟合 Dropout率 0.5（高） 0.3（中） 适度正则，保留更多信息流 参数量 ~280万 ~460万 容量提升65% 设计思想：v2的FC层形成\u0026quot;瓶颈结构\u0026quot;（16384→512→256→10），逐层压缩，比v1的直接压缩（8192→256→10）更平滑。\n四、优化策略（ 调度器进化 ） v2的核心改进 optimizer = optim.Adam(model.parameters(), lr=0.001) # 学习率提升3.3倍 scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10) 调度器对比 # v1: StepLR # Epoch 1-2: lr = 3e-4 # Epoch 3-4: lr = 1.5e-4 # Epoch 5-6: lr = 7.5e-5 # Epoch 7-10: lr = 3.75e-5（过早衰减） # v2: CosineAnnealingLR # lr在10个epoch内从1e-3平滑下降到接近0 # 形成余弦曲线，前期探索，后期精细调整 余弦退火的优势：\n平滑性：避免学习率突变导致loss震荡 探索性：前期较大lr跳出局部最优 精细度：后期小lr稳定收敛 自动化：无需人工设定衰减节点 五、关键问题与建议 仍存在的共通问题 无验证集：训练集=45000，验证集=5000，测试集=10000（推荐拆分） num_workers=0：建议设为num_workers=2或4（看CPU核心数） 无早停：10个epoch可能不够，建议增加到20-30 epoch v2专属建议 学习率适配：CosineAnnealing下，建议epoch至少等于T_max=10，否则学习率未充分衰减 模型保存：大模型更容易过拟合，务必保存最佳model.state_dict() 梯度裁剪：深层网络可加torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)防止梯度爆炸 六、一句话总结 v1是\u0026quot;能用\u0026quot;的入门模型，v2是\u0026quot;好用\u0026quot;的优化模型——通过加深网络、延迟池化、双重Dropout、余弦退火四大改进，在保持代码简洁的同时显著提升了模型容量和训练稳定性，适合作为CIFAR-10的Baseline。\n下附第二版完整代码：\nimport torch import torchvision from torch import nn, optim from torch.utils.data import DataLoader from torchvision import datasets, transforms import numpy as np import random # 固定随机种子 seed = 42 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed(seed) torch.cuda.manual_seed_all(seed) torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False # 使用 GPU device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # 数据加载与增强 transform_train = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)) ]) transform_test = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)) ]) train_set = datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform_train) test_set = datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform_test) train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=0) test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=0) # 模型设计：扩展通道数，增加非线性特征提取层 class CNN(nn.Module): def __init__(self): super().__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(), nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(256 * 8 * 8, 512), nn.ReLU(), nn.Dropout(0.3), nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, 10) ) def forward(self, x): x = self.features(x) x = self.classifier(x) return x model = CNN().to(device) # 优化器和损失函数 criterion = nn.CrossEntropyLoss() optimizer = optim.Adam(model.parameters(), lr=0.001) scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10) # 训练与验证 def train(epoch): model.train() for batch_idx, (inputs, labels) in enumerate(train_loader): inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() if batch_idx % 100 == 0: print(f\u0026#34;Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\u0026#34;) def test(epoch): model.eval() correct, total = 0, 0 with torch.no_grad(): for inputs, labels in test_loader: inputs, labels = inputs.to(device), labels.to(device) outputs = model(inputs) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f\u0026#34;Epoch {epoch}, Accuracy: {100 * correct / total:.2f}%\u0026#34;) for epoch in range(1, 11): train(epoch) test(epoch) scheduler.step() ","permalink":"https://hy4real.github.io/posts/deeplearningday3/","summary":"\u003cp\u003e今日在进行 CIFAR-10 数据集的分类实验，使用 PyTorch 框架进行实验。\n一共做了两个版本的模板，第一版的准确率是 67% 左右，第二版的准确率到了 83.43%。\u003c/p\u003e\n\u003ch2 id=\"第一版\"\u003e第一版\u003c/h2\u003e\n\u003ch3 id=\"一随机种子固定可复现性\"\u003e\u003cstrong\u003e一、随机种子固定（可复现性）\u003c/strong\u003e\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e42\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003enp\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emanual_seed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# ...（更多CUDA种子设置）\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackends\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecudnn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edeterministic\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e作用\u003c/strong\u003e：确保每次运行结果完全一致。\u003cbr\u003e\n\u003cstrong\u003e原理\u003c/strong\u003e：随机数生成器（数据打乱、权重初始化、Dropout等）都从固定起点开始。\u003cbr\u003e\n\u003cstrong\u003e注意\u003c/strong\u003e：\u003ccode\u003ebenchmark=False\u003c/code\u003e会牺牲一点速度换取确定性。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"二设备配置gpu加速\"\u003e\u003cstrong\u003e二、设备配置（GPU加速）\u003c/strong\u003e\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;cuda\u0026#34;\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eis_available\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;cpu\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e作用\u003c/strong\u003e：自动检测并使用GPU，否则用CPU。\u003cbr\u003e\n\u003cstrong\u003e效果\u003c/strong\u003e：GPU可将训练速度提升10-50倍。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"三数据加载与预处理核心部分\"\u003e\u003cstrong\u003e三、数据加载与预处理（核心部分）\u003c/strong\u003e\u003c/h3\u003e\n\u003ch4 id=\"1-数据增强仅训练集\"\u003e\u003cstrong\u003e1. 数据增强（仅训练集）\u003c/strong\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etransform_train\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCompose\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRandomHorizontalFlip\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 50%概率水平翻转（增强泛化）\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRandomCrop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epadding\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 四周填充4像素后随机裁剪回32×32\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eToTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 转为0-1的Tensor [C,H,W]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eNormalize\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.4914\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.4822\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.4465\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 每个通道的均值\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                         \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.2471\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2435\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2616\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 每个通道的标准差\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eCIFAR-10均值/标准差\u003c/strong\u003e：这些是数据集统计值，标准化后数据分布接近标准正态分布，加速收敛。\u003c/p\u003e\n\u003ch4 id=\"2-测试集转换无增强\"\u003e\u003cstrong\u003e2. 测试集转换（无增强）\u003c/strong\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etransform_test\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCompose\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eToTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eNormalize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e...\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e  \u003cspan class=\"c1\"\u003e# 必须与训练集同分布\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"3-dataloader\"\u003e\u003cstrong\u003e3. DataLoader\u003c/strong\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etrain_loader\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etrain_set\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ebatch_size\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eshuffle\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enum_workers\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ebatch_size=128\u003c/code\u003e：每次喂给模型128张图片\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eshuffle=True\u003c/code\u003e：训练集每轮打乱顺序\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enum_workers=0\u003c/code\u003e：数据加载进程数（0表示主进程加载，简单项目够用）\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"四模型架构详解5层cnn\"\u003e\u003cstrong\u003e四、模型架构详解（5层CNN）\u003c/strong\u003e\u003c/h3\u003e\n\u003ch4 id=\"特征提取器\"\u003e\u003cstrong\u003e特征提取器 \u003ccode\u003eself.features\u003c/code\u003e\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003e这里的张量格式遵循 PyTorch 的约定：[B, C, H, W]，其中：\u003c/p\u003e\n\u003cp\u003eB  : Batch Size，批量处理的图片数量；\u003c/p\u003e\n\u003cp\u003eC  : Channels，通道数（如RGB图像为3）；\u003c/p\u003e","title":"深度学习入门 Day 3"},{"content":"相较于 Day 1，mnist_cnn.py 做了两个版本的优化。\n第一版本 第一版本保持了原始代码的简洁性，仅将学习率调度从batch级别修正为epoch级别。\n优化后的精简代码 def train(epoch, model, criterion, optimizer, writer): # ... [原始代码：循环前向/反向/优化] ... # ❌ 移除了 scheduler.step() # 核心修改1 if batch_idx % 100 == 0: # ... [日志记录代码] ... # ... [train函数结束] ... # main 循环部分： for ep in range(1, EPOCHS+1): # ... [train/test调用] ... # ✅ 在epoch结束后调度学习率 # 核心修改2 scheduler.step() # ... [记录学习率 \u0026amp; 打印] ... 在这个参数和修改下，测试准确率达到了99.34%。\n位置 原始代码 优化后代码 意图 train()函数内 scheduler.step()在batch循环中 完全移除 避免学习率下降过快，每个batch都调整会导致训练不稳定 主循环内 无 新增scheduler.step()在epoch末尾 学习率按epoch周期平滑衰减，符合CosineAnnealingLR的设计思想 为何保持其他部分不变？ 无argparse：保持原始硬编码风格，代码更简洁，适合快速实验 无验证集：简化流程，直接5 epoch后看测试集结果（MNIST简单，过拟合风险低） 无数据增强：保持原始数据分布，最直接观察模型对干净数据的拟合能力 总结：此版本改动最小（仅2行代码移动），却修正了最关键的调度逻辑问题，是 性价比最高的优化 。\n第二版本 这个版本的测试准确率提升至99.44%。\n1. 数据增强：泛化能力的基石 # 原代码：仅标准化 train_tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize(...)]) # 改进后： train_tf = transforms.Compose([ transforms.ToTensor(), transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)), # 核心增强 transforms.Normalize((0.1307,), (0.3081,)) ]) 意图与效果：\ndegrees=10：随机旋转±10度，模拟手写笔迹倾斜 translate=(0.1, 0.1)：随机平移10%，模拟数字在画布中的位置偏移 效果：训练集有效扩大10倍，模型被迫学习旋转/平移不变性，测试时对未见过的手写风格更鲁棒 2. 验证集拆分：早停机制的前提 # 原代码：训练集 = 全量60000张 train_ds = datasets.MNIST(...) # 改进后： val_size = int(len(full_train_ds) * 0.2) # 划出20%验证集 train_size = len(full_train_ds) - val_size train_ds, val_ds = random_split(full_train_ds, [train_size, val_size], generator=torch.Generator().manual_seed(args.seed)) 意图与价值：\n验证集作用：作为\u0026quot;模拟考试\u0026quot;，真实反映模型泛化能力 关键细节：使用generator保证拆分可复现，实验结果稳定 早停逻辑：\nfor ep in range(1, args.epochs + 1): train(...) # 训练 val_acc, _ = evaluate(...) # 验证 if val_acc \u0026gt; best_val_acc: # 验证准确率提升？ best_val_acc = val_acc patience_counter = 0 torch.save(model.state_dict(), \u0026#39;mnist_cnn_best.pt\u0026#39;) # 保存最优 else: patience_counter += 1 if patience_counter \u0026gt;= 3: # 连续3轮无提升则停 break 为何能提升准确率：\n防止过拟合：避免模型在训练集上\u0026quot;死记硬背\u0026quot;，在验证集下降时及时停止 模型选择：最终测试的是验证集上最优的模型，而非最后一个epoch的模型 3. 权重衰减（L2正则化） # 原代码： optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) # 改进后： optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4) 意图：\nweight_decay=1e-4：惩罚大权重，迫使模型学习更简单的决策边界 为何能提升准确率：\n数据增强+早停已降低过拟合风险，L2正则化进一步约束模型复杂度 在MNIST这种小数据集上效果更明显 协同效应：与Dropout(0.2)形成双重正则化 4. 性能优化细节 x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True) non_blocking=True：允许CPU-GPU数据传输与计算重叠，潜在提速10-15% 虽然不影响准确率，但能更快完成实验迭代 附上第二版完整代码 import torch, torchvision, time, os from torch import nn from torch.utils.data import DataLoader, random_split from torchvision import datasets, transforms from torch.utils.tensorboard import SummaryWriter import random, numpy as np import matplotlib.pyplot as plt import argparse from torch.optim.lr_scheduler import CosineAnnealingLR # ========== 1. 命令行参数配置 ========== 默认参数下跑了 99.44% def parse_args(): parser = argparse.ArgumentParser(description=\u0026#39;MNIST CNN with improvements\u0026#39;) parser.add_argument(\u0026#39;--batch-size\u0026#39;, type=int, default=128, help=\u0026#39;批大小\u0026#39;) parser.add_argument(\u0026#39;--epochs\u0026#39;, type=int, default=10, help=\u0026#39;训练轮数\u0026#39;) parser.add_argument(\u0026#39;--lr\u0026#39;, type=float, default=0.1, help=\u0026#39;初始学习率\u0026#39;) parser.add_argument(\u0026#39;--seed\u0026#39;, type=int, default=42, help=\u0026#39;随机种子\u0026#39;) parser.add_argument(\u0026#39;--patience\u0026#39;, type=int, default=3, help=\u0026#39;早停耐心轮数\u0026#39;) parser.add_argument(\u0026#39;--val-split\u0026#39;, type=float, default=0.2, help=\u0026#39;验证集比例\u0026#39;) parser.add_argument(\u0026#39;--data-dir\u0026#39;, type=str, default=\u0026#39;data\u0026#39;, help=\u0026#39;数据存储目录\u0026#39;) parser.add_argument(\u0026#39;--log-dir\u0026#39;, type=str, default=\u0026#39;runs\u0026#39;, help=\u0026#39;TensorBoard日志目录\u0026#39;) parser.add_argument(\u0026#39;--save-path\u0026#39;, type=str, default=\u0026#39;mnist_cnn_best.pt\u0026#39;, help=\u0026#39;最佳模型保存路径\u0026#39;) return parser.parse_args() # ========== 2. 可复现性设置 ========== def set_seed(seed): random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed_all(seed) torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False # ========== 3. 数据增强与加载 ========== def get_datasets(data_dir, val_split): # 训练集增强：轻微旋转、平移，提升泛化能力 train_tf = transforms.Compose([ transforms.ToTensor(), transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)), # 核心增强 transforms.Normalize((0.1307,), (0.3081,)) ]) # 验证/测试集：仅标准化，不增强 val_test_tf = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]) # 下载完整训练集 full_train_ds = datasets.MNIST(root=data_dir, train=True, download=True, transform=train_tf) # 拆分训练集与验证集 val_size = int(len(full_train_ds) * val_split) train_size = len(full_train_ds) - val_size train_ds, val_ds = random_split(full_train_ds, [train_size, val_size], generator=torch.Generator().manual_seed(args.seed)) # 测试集 test_ds = datasets.MNIST(root=data_dir, train=False, download=True, transform=val_test_tf) return train_ds, val_ds, test_ds # ========== 4. 模型定义 ========== class Net(nn.Module): def __init__(self): super().__init__() self.features = nn.Sequential( nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2) ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(64 * 7 * 7, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 10) ) def forward(self, x): return self.classifier(self.features(x)) # ========== 5. 训练函数（移除scheduler.step） ========== def train(epoch, model, criterion, optimizer, train_ld, writer, device): model.train() total_loss = 0 for batch_idx, (x, y) in enumerate(train_ld): x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True) optimizer.zero_grad() loss = criterion(model(x), y) loss.backward() optimizer.step() total_loss += loss.item() if batch_idx % 100 == 0: print(f\u0026#39;Epoch {epoch} [{batch_idx * len(x)}/{len(train_ld.dataset)}] \u0026#39; f\u0026#39;Loss: {loss.item():.4f}\u0026#39;) # 记录平均训练损失 writer.add_scalar(\u0026#39;train/loss\u0026#39;, total_loss / len(train_ld), epoch) # ========== 6. 验证/测试函数 ========== @torch.no_grad() def evaluate(epoch, model, criterion, data_ld, writer, device, split_name=\u0026#39;val\u0026#39;): model.eval() correct, total, total_loss = 0, 0, 0 for x, y in data_ld: x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True) out = model(x) loss = criterion(out, y) total_loss += loss.item() _, pred = torch.max(out, 1) total += y.size(0) correct += (pred == y).sum().item() acc = 100. * correct / total avg_loss = total_loss / len(data_ld) print(f\u0026#39;Epoch {epoch} {split_name.capitalize()} Accuracy: {acc:.2f}% | Loss: {avg_loss:.4f}\u0026#39;) writer.add_scalar(f\u0026#39;{split_name}/accuracy\u0026#39;, acc, epoch) writer.add_scalar(f\u0026#39;{split_name}/loss\u0026#39;, avg_loss, epoch) return acc, avg_loss # ========== 7. 错误样本可视化（整合到evaluate） ========== # 在evaluate函数内部，返回acc后追加： # ... [前面代码不变] ... # 收集错误样本（仅测试时） wrong_samples, wrong_labels, wrong_preds = [], [], [] if split_name == \u0026#39;test\u0026#39;: for x, y in data_ld: x, y = x.to(device), y.to(device) out = model(x) _, pred = torch.max(out, 1) wrong_idx = (pred != y).nonzero(as_tuple=True)[0] if len(wrong_samples) \u0026lt; 9 and len(wrong_idx) \u0026gt; 0: need = 9 - len(wrong_samples) take = min(need, len(wrong_idx)) wrong_samples.extend(x[wrong_idx[:take]].cpu()) wrong_labels.extend(y[wrong_idx[:take]].cpu().numpy()) wrong_preds.extend(pred[wrong_idx[:take]].cpu().numpy()) if len(wrong_samples) \u0026gt;= 9: break if len(wrong_samples) \u0026gt;= 9: plt.figure(figsize=(9, 9)) for i in range(9): img = wrong_samples[i].squeeze() plt.subplot(3, 3, i + 1) plt.imshow(img, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;T:{wrong_labels[i]} P:{wrong_preds[i]}\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.savefig(\u0026#39;wrong_cases.png\u0026#39;, dpi=120) plt.close() print(\u0026#34;已保存错误样本图：wrong_cases.png\u0026#34;) return acc # ========== 8. 主函数 ========== def main(args): # 设置随机种子 set_seed(args.seed) # 设备 device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) print(f\u0026#34;Using {device} | PyTorch {torch.__version__}\u0026#34;) # 数据加载 train_ds, val_ds, test_ds = get_datasets(args.data_dir, args.val_split) train_ld = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True) val_ld = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=0, pin_memory=True) test_ld = DataLoader(test_ds, batch_size=args.batch_size, shuffle=False, num_workers=0, pin_memory=True) # 模型、损失、优化器、调度器 model = Net().to(device) criterion = nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4) scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs) # TensorBoard writer = SummaryWriter(args.log_dir) # ========== 9. 早停逻辑 ========== best_val_acc = 0.0 patience_counter = 0 for ep in range(1, args.epochs + 1): print(f\u0026#34;\\n{\u0026#39;=\u0026#39; * 50}\\nEpoch {ep}/{args.epochs}\\n{\u0026#39;=\u0026#39; * 50}\u0026#34;) # 训练 train(ep, model, criterion, optimizer, train_ld, writer, device) # 验证（每个epoch后） val_acc, val_loss = evaluate(ep, model, criterion, val_ld, writer, device, \u0026#39;val\u0026#39;) # 学习率调度（移到epoch级别） scheduler.step() current_lr = optimizer.param_groups[0][\u0026#39;lr\u0026#39;] writer.add_scalar(\u0026#39;train/lr\u0026#39;, current_lr, ep) print(f\u0026#39;Current LR: {current_lr:.6f}\u0026#39;) # 早停检查 if val_acc \u0026gt; best_val_acc: best_val_acc = val_acc patience_counter = 0 torch.save(model.state_dict(), args.save_path) # 保存最佳模型 print(f\u0026#39;✓ 验证准确率提升，模型已保存至 {args.save_path}\u0026#39;) else: patience_counter += 1 print(f\u0026#39;✗ 验证准确率未提升，耐心计数: {patience_counter}/{args.patience}\u0026#39;) if patience_counter \u0026gt;= args.patience: print(f\u0026#34;早停触发！最佳验证准确率: {best_val_acc:.2f}%\u0026#34;) break # ========== 10. 最终测试 ========== print(\u0026#34;\\n加载最佳模型进行最终测试...\u0026#34;) model.load_state_dict(torch.load(args.save_path, map_location=device, weights_only=True)) test_acc, _ = evaluate(ep, model, criterion, test_ld, writer, device, \u0026#39;test\u0026#39;) print(f\u0026#34;最终测试准确率: {test_acc:.2f}%\u0026#34;) writer.close() print(\u0026#34;\\n训练完成！\u0026#34;) # ========== 入口 ========== if __name__ == \u0026#39;__main__\u0026#39;: args = parse_args() print(\u0026#34;配置参数:\u0026#34;, vars(args)) main(args) ","permalink":"https://hy4real.github.io/posts/deeplearningday2/","summary":"\u003cp\u003e相较于 Day 1，mnist_cnn.py 做了两个版本的优化。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"第一版本\"\u003e第一版本\u003c/h2\u003e\n\u003cp\u003e第一版本保持了原始代码的简洁性，仅将学习率调度从\u003ccode\u003ebatch\u003c/code\u003e级别修正为\u003ccode\u003eepoch\u003c/code\u003e级别。\u003c/p\u003e\n\u003ch3 id=\"优化后的精简代码\"\u003e\u003cstrong\u003e优化后的精简代码\u003c/strong\u003e\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etrain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eepoch\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecriterion\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eoptimizer\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewriter\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# ... [原始代码：循环前向/反向/优化] ...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# ❌ 移除了 scheduler.step()  # 核心修改1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ebatch_idx\u003c/span\u003e \u003cspan class=\"o\"\u003e%\u003c/span\u003e \u003cspan class=\"mi\"\u003e100\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"c1\"\u003e# ... [日志记录代码] ...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# ... [train函数结束] ...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# main 循环部分：\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eep\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eEPOCHS\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# ... [train/test调用] ...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# ✅ 在epoch结束后调度学习率  # 核心修改2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003escheduler\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estep\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"c1\"\u003e# ... [记录学习率 \u0026amp; 打印] ...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e在这个参数和修改下，测试准确率达到了99.34%。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e位置\u003c/th\u003e\n          \u003cth\u003e原始代码\u003c/th\u003e\n          \u003cth\u003e优化后代码\u003c/th\u003e\n          \u003cth\u003e意图\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003etrain()函数内\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003ccode\u003escheduler.step()\u003c/code\u003e在batch循环中\u003c/td\u003e\n          \u003ctd\u003e\u003cstrong\u003e完全移除\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e避免学习率下降过快，每个batch都调整会导致训练不稳定\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e主循环内\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e无\u003c/td\u003e\n          \u003ctd\u003e\u003cstrong\u003e新增\u003c/strong\u003e\u003ccode\u003escheduler.step()\u003c/code\u003e在epoch末尾\u003c/td\u003e\n          \u003ctd\u003e学习率按epoch周期平滑衰减，符合CosineAnnealingLR的设计思想\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003chr\u003e\n\u003ch3 id=\"为何保持其他部分不变\"\u003e\u003cstrong\u003e为何保持其他部分不变？\u003c/strong\u003e\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e无argparse\u003c/strong\u003e：保持原始硬编码风格，代码更简洁，适合快速实验\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e无验证集\u003c/strong\u003e：简化流程，直接5 epoch后看测试集结果（MNIST简单，过拟合风险低）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e无数据增强\u003c/strong\u003e：保持原始数据分布，最直接观察模型对干净数据的拟合能力\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e：此版本\u003cstrong\u003e改动最小（仅2行代码移动）\u003c/strong\u003e，却修正了最关键的调度逻辑问题，是 \u003cstrong\u003e性价比最高的优化\u003c/strong\u003e 。\u003c/p\u003e","title":"深度学习入门 Day 2"},{"content":" 一、整体概述 这是一个完整的MNIST手写数字分类项目，使用PyTorch构建了一个小型卷积神经网络(CNN)。代码实现了数据加载、模型训练、测试评估、可视化错误样本和日志记录的全流程，非常适合作为深度学习入门范例。\n二、逐部分详细解析 1. 导入库 (Lines 1-7) import torch, torchvision, time, os from torch import nn from torch.utils.data import DataLoader from torchvision import datasets, transforms from torch.utils.tensorboard import SummaryWriter import random, numpy as np import matplotlib.pyplot as plt 功能：导入所有必需的工具库。\n设计意图：\ntorch \u0026amp; torchvision: PyTorch核心框架和计算机视觉工具 time, os: 基础系统功能（虽然代码中没直接用，但为扩展预留） SummaryWriter: 连接TensorBoard，实时可视化训练曲线 random, numpy: 用于设置随机种子，保证结果可复现 matplotlib: 绘制错误样本图，直观观察模型弱点 2. 随机种子设置 (Lines 9-16) seed = 42 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) # CPU 权重 torch.cuda.manual_seed(seed) # GPU 权重 torch.cuda.manual_seed_all(seed) # 多 GPU torch.backends.cudnn.deterministic = True # 卷积确定 torch.backends.cudnn.benchmark = False device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) print(\u0026#34;Using\u0026#34;, device) 功能：强制所有随机性来源产生确定性结果，并自动选择运算设备。\n意图详解：\n可复现性：深度学习实验依赖大量随机初始化，不设置种子的话，每次运行结果都不同，无法对比调参效果 多层保险：分别设置Python、numpy、PyTorch CPU/GPU的随机种子，确保无死角 cuDNN设置： deterministic = True: 牺牲一点速度，确保卷积等操作的算法是确定的 benchmark = False: 禁止自动选择最优算法，避免非确定性 设备选择：自动检测GPU，有则用GPU加速，无则 fallback 到CPU，提升代码兼容性 3. 超参数配置 (Lines 18-21) BATCH_SIZE = 128 EPOCHS = 5 LR = 0.1 功能：集中管理训练参数。\n在这个参数配置下，准确率达到了99.05%。\n4. 数据加载与预处理 (Lines 23-35) tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) train_ds = datasets.MNIST(root=\u0026#39;data\u0026#39;, train=True, download=True, transform=tf) test_ds = datasets.MNIST(root=\u0026#39;data\u0026#39;, train=False, download=True, transform=tf) # FIX-1: num_workers=0 禁用多进程 train_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True) test_ld = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True) 功能：下载数据集，转换格式，封装成可迭代的数据加载器。\n逐行拆解：\ntransforms.ToTensor(): 将PIL图片(0-255)转为PyTorch张量(0.0-1.0)，并调整维度为[C, H, W] transforms.Normalize((0.1307,), (0.3081,)): 关键步骤，对数据进行标准化 0.1307 是MNIST训练集的均值，0.3081 是标准差 意图：让数据分布接近标准正态分布，加速训练收敛，提升稳定性 为什么是单值？因为MNIST是灰度图，单通道；彩色图会是3个值如(0.5,0.5,0.5) datasets.MNIST(...): 自动从网络下载数据集到./data文件夹 DataLoader : shuffle=True: 训练集打乱顺序，避免模型学到顺序偏见 num_workers=0 : Windows系统下的重要修复。多进程加载数据在Windows上容易因fork机制崩溃，设为0可确保稳定 pin_memory=True: 将数据锁页在内存，加速向GPU的传输 5. 模型定义 (Lines 37-48) class Net(nn.Module): def __init__(self): super().__init__() self.features = nn.Sequential( nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2) ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(64*7*7, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 10) ) def forward(self, x): return self.classifier(self.features(x)) 功能：定义一个简洁高效的CNN架构。\n结构解析：\nself.features : 特征提取层 Conv2d(1,32,3,padding=1): 输入1通道(灰度)，输出32通道，3x3卷积，padding=1保持尺寸不变 MaxPool2d(2): 2x2最大池化，尺寸减半（28x28 → 14x14） Conv2d(32,64,3,padding=1): 通道数升维到64 第二次池化后尺寸: 14x14 → 7x7 self.classifier : 分类头 nn.Flatten(): 展平特征图，64*7*7 = 3136个特征 nn.Linear(3136,128): 全连接层降维到128 nn.Dropout(0.2): 防止过拟合，训练时随机丢弃20%神经元 nn.Linear(128,10): 输出10个类别得分（对应数字0-9） 意图：这是经典的LeNet现代化变体，结构清晰，参数少（约20万），在MNIST上足够强大且训练快速。\n6. 训练函数 (Lines 50-61) def train(epoch, model, criterion, optimizer, writer): model.train() for batch_idx, (x, y) in enumerate(train_ld): x, y = x.to(device), y.to(device) optimizer.zero_grad() loss = criterion(model(x), y) loss.backward() optimizer.step() scheduler.step() if batch_idx % 100 == 0: print(f\u0026#39;Epoch {epoch} [{batch_idx*len(x)}/{len(train_ld.dataset)}] \u0026#39; f\u0026#39;Loss: {loss.item():.4f}\u0026#39;) writer.add_scalar(\u0026#39;train/loss\u0026#39;, loss.item(), epoch*len(train_ld)+batch_idx) 功能：执行一个训练轮次，更新模型权重。\n流程详解：\nmodel.train(): 开启训练模式（启用Dropout等） 遍历train_ld，每次取BATCH_SIZE个样本 x.to(device): 把数据搬到GPU/CPU optimizer.zero_grad(): 清空梯度，防止梯度累积 criterion(model(x), y): 前向传播+计算交叉熵损失 loss.backward(): 反向传播，计算梯度 optimizer.step(): 根据梯度更新权重 scheduler.step(): 调整学习率（每个batch都调，注意：通常按epoch调更常见，但这样也行） 每100个batch打印日志，并写入TensorBoard（全局步数=epoch*总batch数+当前batch数） 意图：标准的训练循环，代码紧凑，注释清晰，适合教学。\n7. 测试函数 (Lines 63-98) @torch.no_grad() def test(epoch, model, writer, test_ld, device): model.eval() correct, total = 0, 0 wrong_samples = [] # 存储错误样本的特征（x） wrong_labels = [] # 存储错误样本的真实标签（y） wrong_preds = [] # 存储错误样本的预测标签（pred） # ... 遍历测试集 ... if len(wrong_samples) \u0026gt;= 9: plt.figure(figsize=(9, 9)) for i in range(9): img = wrong_samples[i].squeeze() plt.subplot(3, 3, i + 1) plt.imshow(img, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;T:{label} P:{guess}\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.savefig(\u0026#39;wrong_cases.png\u0026#39;, dpi=120) plt.close() 功能：评估模型性能，并可视化典型错误样本。\n亮点解析：\n@torch.no_grad() : 性能优化，禁用梯度计算，节省内存，提速30%以上 model.eval(): 切换到评估模式（关闭Dropout） 错误样本收集：这是本代码的核心价值之一 只收集9个错误样本，避免内存爆炸 用nonzero(as_tuple=True)[0]找到预测≠真实的索引 存储原始图像、真实标签、预测标签到CPU，便于后续绘图 可视化：绘制3x3网格，展示模型最容易混淆的手写数字 squeeze(): 去除通道维度（1,28,28 → 28,28） cmap='gray': 灰度图显示 plt.close(): 防止内存泄漏，释放图形资源 日志记录：将准确率写入TensorBoard 意图：不仅输出数字指标，还让开发者直观理解模型弱点（比如是7被认成9，还是3被认成8），指导后续改进方向。\n8. 主程序保护壳 (Lines 100-110) if __name__ == \u0026#39;__main__\u0026#39;: from torch.optim.lr_scheduler import CosineAnnealingLR model = Net().to(device) criterion = nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS) writer = SummaryWriter(\u0026#39;runs\u0026#39;) for ep in range(1, EPOCHS+1): train(ep, model, criterion, optimizer, writer) test(ep, model, writer, test_ld, device) torch.save(model.state_dict(), \u0026#39;mnist_cnn.pt\u0026#39;) writer.close() 功能：组织训练流程，保存结果。\n关键点：\nif __name__ == '__main__' : Windows多进程必备。没有这个，在Windows上运行会报错或产生僵尸进程 学习率调度器：CosineAnnealingLR实现余弦退火 学习率从初始值平滑下降到接近0，像cos曲线 意图：前期快速探索，后期精细调整， often 比固定学习率效果好 注意：T_max=EPOCHS表示在整个训练周期内完成一个余弦周期 优化器：SGD with Momentum (momentum=0.9)，经典且有效的组合 模型保存：只保存权重(state_dict)而非整个模型，更轻量且跨平台兼容 writer.close(): 确保日志文件正确写入并释放资源 三、核心设计哲学总结 设计点 意图与价值 确定性训练 让实验可复现，科学调参 Windows兼容 num_workers=0 + if __name__ 确保跨平台稳定 可视化洞察 TensorBoard + 错误样本图，不只是看Loss/Acc，更理解模型行为 模块化 数据、模型、训练、测试分离，便于复用和扩展 防御性编程 检查错误样本数量、及时plt.close()、writer.close()，避免资源泄漏 ","permalink":"https://hy4real.github.io/posts/deeplearningday1/","summary":"\u003chr\u003e\n\u003ch2 id=\"一整体概述\"\u003e一、整体概述\u003c/h2\u003e\n\u003cp\u003e这是一个\u003cstrong\u003e完整的MNIST手写数字分类项目\u003c/strong\u003e，使用PyTorch构建了一个小型卷积神经网络(CNN)。代码实现了数据加载、模型训练、测试评估、可视化错误样本和日志记录的全流程，非常适合作为深度学习入门范例。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"二逐部分详细解析\"\u003e二、逐部分详细解析\u003c/h2\u003e\n\u003ch3 id=\"1-导入库-lines-1-7\"\u003e\u003cstrong\u003e1. 导入库 (Lines 1-7)\u003c/strong\u003e\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003etorchvision\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003etime\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003eos\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003enn\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.utils.data\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eDataLoader\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorchvision\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edatasets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.utils.tensorboard\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eSummaryWriter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003enumpy\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003enp\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ematplotlib.pyplot\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003eplt\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e功能\u003c/strong\u003e：导入所有必需的工具库。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e设计意图\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etorch\u003c/code\u003e \u0026amp; \u003ccode\u003etorchvision\u003c/code\u003e: PyTorch核心框架和计算机视觉工具\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etime, os\u003c/code\u003e: 基础系统功能（虽然代码中没直接用，但为扩展预留）\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSummaryWriter\u003c/code\u003e: 连接TensorBoard，实时可视化训练曲线\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erandom, numpy\u003c/code\u003e: 用于设置随机种子，保证结果可复现\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ematplotlib\u003c/code\u003e: 绘制错误样本图，直观观察模型弱点\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"2-随机种子设置-lines-9-16\"\u003e\u003cstrong\u003e2. 随机种子设置 (Lines 9-16)\u003c/strong\u003e\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e42\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003enp\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emanual_seed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e          \u003cspan class=\"c1\"\u003e# CPU 权重\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emanual_seed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e     \u003cspan class=\"c1\"\u003e# GPU 权重\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emanual_seed_all\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 多 GPU\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackends\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecudnn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edeterministic\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e   \u003cspan class=\"c1\"\u003e# 卷积确定\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackends\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecudnn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebenchmark\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;cuda\u0026#34;\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eis_available\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;cpu\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Using\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e功能\u003c/strong\u003e：\u003cstrong\u003e强制所有随机性来源产生确定性结果\u003c/strong\u003e，并自动选择运算设备。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e意图详解\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e可复现性\u003c/strong\u003e：深度学习实验依赖大量随机初始化，不设置种子的话，每次运行结果都不同，无法对比调参效果\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e多层保险\u003c/strong\u003e：分别设置Python、\u003ccode\u003enumpy\u003c/code\u003e、PyTorch CPU/GPU的随机种子，确保无死角\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ecuDNN设置\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edeterministic = True\u003c/code\u003e: 牺牲一点速度，确保卷积等操作的算法是确定的\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebenchmark = False\u003c/code\u003e: 禁止自动选择最优算法，避免非确定性\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e设备选择\u003c/strong\u003e：自动检测GPU，有则用GPU加速，无则 fallback 到CPU，提升代码兼容性\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"3-超参数配置-lines-18-21\"\u003e\u003cstrong\u003e3. 超参数配置 (Lines 18-21)\u003c/strong\u003e\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eBATCH_SIZE\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eEPOCHS\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eLR\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e功能\u003c/strong\u003e：集中管理训练参数。\u003c/p\u003e","title":"深度学习入门 Day 1"},{"content":"从合肥到杭州，从紫金港到玉泉，人们或许更容易感受到空间的转换而忽略了时刻流逝的时间，以至于回头看才开始感叹时光荏苒，我的本科四年亦是如此。我尝试着像写论文一样给我的本科写一段摘要、找几个关键词，只不过“话从哪里说起？等到你要说话，什么话都是那样渺茫地找不到个源头”。\n回顾我的本科岁月，很多事我都记不起，我记得的是一些瞬间：比如在团委例会的时刻，比如支教时孩子们的笑脸，比如沉浸在连麦游戏的时光，比如玉泉斑驳的砖瓦、上了苔藓的树干，比如和朋友交心的夜。\n在学校里的时间占了大多数，没有多多感受杭州这座城是我的遗憾。杭州是一个美丽的城市。和部门同学在中秋节清晨登上宝石山看的日出，夜游的西溪湿地，陪高中好友走过的孤山和苏堤，植物园“玉泉”庭院里硕大的金鱼，玉泉后的老和云起，乌龟潭某间亭子里拉二胡的老爷爷，虎跑公园观音殿前的藤萝，灵隐寺从不断绝的清香，九溪烟树望不尽的绿，云雾缭绕的十里琅珰，清幽的云栖竹径，冒雨爬上玉皇山顶后放晴的蓝天……我实在列举不完。我会很想念这里。\n四年前，我听着痛仰乐队的《西湖》来到杭州；三年前，学长推荐，我开始听达达乐队的《南方》。这两首歌贯穿了我的本科生活。\n“那一天那一夜，没有察觉竟已走远；那一天那一夜，从我的故事里走远。”\n“就这样一天天浪漫，这样一天天感叹。没有什么是最重要，日子随着阴晴变换。时间过得飞快，转眼这些已成回忆；每天都有新的问题，不知何时又会再忆起 —— 南方……”\n我想浙大和杭州会成为我永远的南方。\n2025 年 6 月 22 日夜于玉泉 430\n","permalink":"https://hy4real.github.io/posts/gradthoughts/","summary":"\u003cp\u003e从合肥到杭州，从紫金港到玉泉，人们或许更容易感受到空间的转换而忽略了时刻流逝的时间，以至于回头看才开始感叹时光荏苒，我的本科四年亦是如此。我尝试着像写论文一样给我的本科写一段摘要、找几个关键词，只不过“话从哪里说起？等到你要说话，什么话都是那样渺茫地找不到个源头”。\u003c/p\u003e\n\u003cp\u003e回顾我的本科岁月，很多事我都记不起，我记得的是一些瞬间：比如在团委例会的时刻，比如支教时孩子们的笑脸，比如沉浸在连麦游戏的时光，比如玉泉斑驳的砖瓦、上了苔藓的树干，比如和朋友交心的夜。\u003c/p\u003e\n\u003cp\u003e在学校里的时间占了大多数，没有多多感受杭州这座城是我的遗憾。杭州是一个美丽的城市。和部门同学在中秋节清晨登上宝石山看的日出，夜游的西溪湿地，陪高中好友走过的孤山和苏堤，植物园“玉泉”庭院里硕大的金鱼，玉泉后的老和云起，乌龟潭某间亭子里拉二胡的老爷爷，虎跑公园观音殿前的藤萝，灵隐寺从不断绝的清香，九溪烟树望不尽的绿，云雾缭绕的十里琅珰，清幽的云栖竹径，冒雨爬上玉皇山顶后放晴的蓝天……我实在列举不完。我会很想念这里。\u003c/p\u003e\n\u003cp\u003e四年前，我听着痛仰乐队的《西湖》来到杭州；三年前，学长推荐，我开始听达达乐队的《南方》。这两首歌贯穿了我的本科生活。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“那一天那一夜，没有察觉竟已走远；那一天那一夜，从我的故事里走远。”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“就这样一天天浪漫，这样一天天感叹。没有什么是最重要，日子随着阴晴变换。时间过得飞快，转眼这些已成回忆；每天都有新的问题，不知何时又会再忆起 —— 南方……”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e我想浙大和杭州会成为我永远的南方。\u003c/p\u003e\n\u003cp\u003e2025 年 6 月 22 日夜于玉泉 430\u003c/p\u003e","title":"没有察觉，竟已走远"},{"content":"写完毕设以后闲来无事，想着去一趟南京找好兄弟散散心。订好酒店和车票，我在 5 月 14 日的清晨离开杭州，前往南京。\n这并不是我第一次去南京，以前上初中时候周末去过一次，从合肥坐大巴车要花费一上午时间才到达那里，下午爬了一下中山陵，看了一下南京古城墙，就回去了。现在并不记得当时的细节了，只记得带回来一块刻着“天才在于勤奋，聪明在于积累”的雨花石，以及中山陵那望不到头的一级级楼梯。\n见到朋友以后很开心。我把行李放好后，就听他的指示到一个又一个景点去。\n先是颐和路周围，粉刷的不黄不白的墙，偶尔开在墙边的一株两株花朵，不成规模的行道树，这竟然就被某些人趋之若鹜称为景点，还有人排队拍照。我叹为观止。\n紧接着是去先锋书店，一个地下车库改造的网红书店，在书店的某个区域里，悬挂着别人写下心情与故事的明信片。确实也对得上网红一词，在一堆明信片里找到一份求而不得的心碎瞬间，配上一首伤感的降速降调情歌，一个抖音大爆单视频就做好了。或许这不是书店的问题，或许也不仅仅是书店的问题，我只是习惯抱怨、习惯感叹。\n玄武湖挺让人失望的，明明有皇家园林的身份做背书，呈现出的效果却并非如此：小孩子才喜欢的鸭子造型的载人船，不开门的游乐园，莫名其妙响起来的流行音乐……我不知道为什么要这样去设计一个景点，无论是商业化还是别的方面都很难让人认可。\n下午的南大鼓楼校区是蛮好的，静静的，嚼得菜根，做得大事。\n鸡鸣寺应该是仗着自己在南京的名声比较好，所以无论是门票还是周边文创的价格都比灵隐和法喜贵两三倍。给人祈祷点香火的炉子竟然是一个没有顶的大炉子，虔诚的信徒只能把三根香远远地投进去，不知道是在上香还是投标枪。\n晚上我们去了夫子庙和秦淮河，目光所及之处游人如织，金碧辉煌的布置。本来抱着“泛舟于河上”的幻想，看见现代化的游船载着几十人快速地从身边呼啸而过，我便说不出话了，这和在《桨声灯影里的秦淮河》真是截然不同了：\n从两重玻璃里映出那辐射着的黄黄的散光，反晕出一片朦胧的烟霭；透过这烟霭，在黯黯的水波里，又逗起缕缕的明漪。在这薄霭和微漪里，听着那悠然的间歇的桨声，谁能不被引入他的美梦去呢？\n第二天去了仙林校区，整体设计是很符合学生生活学习的，这点上比紫金港做得要好。\n下午的明孝陵挺惊喜的，景色引人，五彩缤纷的花朵，自由自在的天鹅和野鸭，性情温顺的梅花鹿，可惜是来的季节并不完美，错过了春天的樱花展和冬天的梅花园。\n从明孝陵出来，顺着翠绿的朦胧的梧桐大道往上走，简单参观了一下美龄宫和音乐台，并没有特别的感受。\n需要多提一嘴，在南京的多个景区，我都会碰见主动上前揽客的人，或者问我们需不需要拍照，或者问我们需不需要租车，不能否认他们迎合了很多人的需求，如果没有市场，想必他们也不会以此为生意，但是有人喜欢就有人讨厌——对于一个在杭州待了快四年的人，我实在难以接受这种没有管制的景点。在秦淮河畔，听见了以下的一段对话：“刚刚我碰到个游客，他说有人拍照只收十块钱。”“是谁只收十块钱的？你全家死了。”我和朋友忍俊不禁。\n在六朝古都的两天两夜，我却并没有感觉到任何古色古香的沉淀，感受最大的竟是浮躁，不知道是不是一种讽刺。朋友说我是被杭州和西湖惯坏了，或许确实如此，我对杭州和西湖寄托太多感情了。\n今天是朋友的生日，我在这里祝他生日快乐。今年秋天他会来浙大读研，虽然是在萧山的水博园，位置很偏僻，但我希望他能在杭州的三年时间充分感受这座城市。也许他会在之后理解我游览南京之后的感受。\n2025年5月16日于杭州\n","permalink":"https://hy4real.github.io/posts/nanjingtour/","summary":"\u003cp\u003e写完毕设以后闲来无事，想着去一趟南京找好兄弟散散心。订好酒店和车票，我在 5 月 14 日的清晨离开杭州，前往南京。\u003c/p\u003e\n\u003cp\u003e这并不是我第一次去南京，以前上初中时候周末去过一次，从合肥坐大巴车要花费一上午时间才到达那里，下午爬了一下中山陵，看了一下南京古城墙，就回去了。现在并不记得当时的细节了，只记得带回来一块刻着“天才在于勤奋，聪明在于积累”的雨花石，以及中山陵那望不到头的一级级楼梯。\u003c/p\u003e\n\u003cp\u003e见到朋友以后很开心。我把行李放好后，就听他的指示到一个又一个景点去。\u003c/p\u003e\n\u003cp\u003e先是颐和路周围，粉刷的不黄不白的墙，偶尔开在墙边的一株两株花朵，不成规模的行道树，这竟然就被某些人趋之若鹜称为景点，还有人排队拍照。我叹为观止。\u003c/p\u003e\n\u003cp\u003e紧接着是去先锋书店，一个地下车库改造的网红书店，在书店的某个区域里，悬挂着别人写下心情与故事的明信片。确实也对得上网红一词，在一堆明信片里找到一份求而不得的心碎瞬间，配上一首伤感的降速降调情歌，一个抖音大爆单视频就做好了。或许这不是书店的问题，或许也不仅仅是书店的问题，我只是习惯抱怨、习惯感叹。\u003c/p\u003e\n\u003cp\u003e玄武湖挺让人失望的，明明有皇家园林的身份做背书，呈现出的效果却并非如此：小孩子才喜欢的鸭子造型的载人船，不开门的游乐园，莫名其妙响起来的流行音乐……我不知道为什么要这样去设计一个景点，无论是商业化还是别的方面都很难让人认可。\u003c/p\u003e\n\u003cp\u003e下午的南大鼓楼校区是蛮好的，静静的，嚼得菜根，做得大事。\u003c/p\u003e\n\u003cp\u003e鸡鸣寺应该是仗着自己在南京的名声比较好，所以无论是门票还是周边文创的价格都比灵隐和法喜贵两三倍。给人祈祷点香火的炉子竟然是一个没有顶的大炉子，虔诚的信徒只能把三根香远远地投进去，不知道是在上香还是投标枪。\u003c/p\u003e\n\u003cp\u003e晚上我们去了夫子庙和秦淮河，目光所及之处游人如织，金碧辉煌的布置。本来抱着“泛舟于河上”的幻想，看见现代化的游船载着几十人快速地从身边呼啸而过，我便说不出话了，这和在《桨声灯影里的秦淮河》真是截然不同了：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e从两重玻璃里映出那辐射着的黄黄的散光，反晕出一片朦胧的烟霭；透过这烟霭，在黯黯的水波里，又逗起缕缕的明漪。在这薄霭和微漪里，听着那悠然的间歇的桨声，谁能不被引入他的美梦去呢？\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e第二天去了仙林校区，整体设计是很符合学生生活学习的，这点上比紫金港做得要好。\u003c/p\u003e\n\u003cp\u003e下午的明孝陵挺惊喜的，景色引人，五彩缤纷的花朵，自由自在的天鹅和野鸭，性情温顺的梅花鹿，可惜是来的季节并不完美，错过了春天的樱花展和冬天的梅花园。\u003c/p\u003e\n\u003cp\u003e从明孝陵出来，顺着翠绿的朦胧的梧桐大道往上走，简单参观了一下美龄宫和音乐台，并没有特别的感受。\u003c/p\u003e\n\u003cp\u003e需要多提一嘴，在南京的多个景区，我都会碰见主动上前揽客的人，或者问我们需不需要拍照，或者问我们需不需要租车，不能否认他们迎合了很多人的需求，如果没有市场，想必他们也不会以此为生意，但是有人喜欢就有人讨厌——对于一个在杭州待了快四年的人，我实在难以接受这种没有管制的景点。在秦淮河畔，听见了以下的一段对话：“刚刚我碰到个游客，他说有人拍照只收十块钱。”“是谁只收十块钱的？你全家死了。”我和朋友忍俊不禁。\u003c/p\u003e\n\u003cp\u003e在六朝古都的两天两夜，我却并没有感觉到任何古色古香的沉淀，感受最大的竟是浮躁，不知道是不是一种讽刺。朋友说我是被杭州和西湖惯坏了，或许确实如此，我对杭州和西湖寄托太多感情了。\u003c/p\u003e\n\u003cp\u003e今天是朋友的生日，我在这里祝他生日快乐。今年秋天他会来浙大读研，虽然是在萧山的水博园，位置很偏僻，但我希望他能在杭州的三年时间充分感受这座城市。也许他会在之后理解我游览南京之后的感受。\u003c/p\u003e\n\u003cp\u003e2025年5月16日于杭州\u003c/p\u003e","title":"金陵游"},{"content":"自从去年十二月底考研初试结束以后，原本以为可以如释重负，然而达摩克里斯之剑好像只是掉下来了一点，更加让人焦虑。在新学期的第一天，我原本打算继续在寝室里，准备着毕设和复试的琐碎事情，继续被接连不断的截止日期所驱动，然而中午在微信里看到了西湖旅游的推文：《2025年西湖第一场花事》，心里便想着给自己放个假，一次独属自己的假期，而不用像寒假那样走亲访友的疲倦。这样想着，我吃完午饭就出发了。\n一开始打算再去一遍孤山，梅妻鹤子，后来一想还是太冷清了，只怕我看完后会更难过，我选了离我们玉泉校区更近的植物园。于是带着几分自由，几分洒脱，我不慌不忙地走走停停。在24年下半年，高压的备考生活让我开始注意玉泉的景色，斑驳的墙壁，红白砖瓦的屋顶，屋檐上对称的脊兽，一切都在时间的长河里洗过了一遍。无论是百年老树上的苔藓和绿草，还是桂花上附着的雨水，都让我愈加喜欢这个古朴宁静的校区。我顺着智泉路一直往南走，路上碰见许多株梅花，有零星开着的，有簇在一起开得热烈而颇成气候的。\n从南门出去，沿着青芝坞街道的玉泉路往西行一小会儿，就到了植物园的一个小入口。来玉泉一年半了，我倒是从未料想学校离植物园如此近，也是遗憾没能早来，以往被作业拖累的三点一线的生活还是太让人沮丧了。凭本科学生证，门票只用半价，不过本科要很快结束了。\n进到植物园内，便感到天地辽阔，大片大片的空白。果然，人还是要经常到没有天花板的地方，在宿舍、教室那样逼仄的地方待时间长了，不免压抑。我没有按照推文里推荐的那般直奔灵峰景区，想着离开前总会去到那，踏上了一条人更少的路。杭州植物园依着西湖山水而建，台阶很多，路边的树大多只剩孤零零的树干，偶有一两株梅花点缀。不知爬了多少级台阶，在我眼前突然浮现出一座曲桥，紧接着是长长的亭廊，往前走是江南园林熟悉的框景，就这样把小岛、湖面全部框起来。环湖一圈，步移景异，意趣横生。\n正打算原路返回时，看见一块牌匾上写着“玉泉鱼跃”，我不禁想到我校区的名字，难道这之间有什么联系吗？怀着疑问，我继续往前走。进门就有一个大的窗框，后面天井内有湖石一块，翠竹数竿，内有几个庭院，庭院间用回廊、白墙相隔，墙上有漏窗引景，使几个庭院隔而不绝，给人以庭院深深之感。进门后先至玉泉池，名**“鱼乐国”**，池子里数鱼游弋，有巨大的青鱼，还有漂亮的金鱼、鲤鱼，可一饱眼福。还有珍珠泉和晴空细雨泉，可惜今天雾蒙蒙的，没赶上最美的时候。\n在转了景点一圈后才知道玉泉的历史，玉泉是西湖三大名泉之一，因泉水晶莹透明，犹如美玉而得名。白居易有诗《题玉泉寺》云：\n湛湛玉泉色，悠悠浮云身。闲心对定水，清净两无尘。手把青筇杖，头戴白纶巾。兴尽下山去，知我是谁人。\n在“玉泉”的匾额两边有楹联：\n鱼乐机浑忘，泉流玉有声。\n读着这些文字，看着如许景色，真是洗涤心灵。\n回去看灵峰探梅，灵峰的梅，得一个“满”字。山上山下，漫山遍野，处处是梅林雪海。选一朵花嗅闻，馥郁芬芳，瞬间弥漫在鼻尖，那是梅林深处最纯粹的气息，仿佛将整个冬日的浪漫与温暖，都凝聚在此。\n走到灵峰最深处，工作人员提醒我已经到了植物园的出口，要么原路返回，要么往山上走。我问山上可以通向哪，他说可以走到老和山，我大喜，真是“山重水复疑无路，柳暗花明又一村”，我知道学校有一个门就可以通向老和山。全然不顾走了两三个小时的疲乏，我只身一人坚定往山上爬去。在山上俯瞰整个杭州，远处是模糊的西湖和雷峰塔，感到前所未有的酣畅，爬山的意义在山顶就这样显现。路上打照面碰见一个四十多岁的叔叔，问他老和山在前面吗，他说是，因为他就是从老和山校门走过来的。感叹巧合之余，不知为何，我脑中想起王维的《终南别业》：\n偶然值林叟，谈笑无还期。\n或许是这字句之间也透着一种随性和偶然的快乐。\n乘兴而行，意犹未尽，心潮澎湃，遂作此文。\n","permalink":"https://hy4real.github.io/posts/feb.17th/","summary":"\u003cp\u003e自从去年十二月底考研初试结束以后，原本以为可以如释重负，然而达摩克里斯之剑好像只是掉下来了一点，更加让人焦虑。在新学期的第一天，我原本打算继续在寝室里，准备着毕设和复试的琐碎事情，继续被接连不断的截止日期所驱动，然而中午在微信里看到了西湖旅游的推文：《2025年西湖第一场花事》，心里便想着给自己放个假，一次独属自己的假期，而不用像寒假那样走亲访友的疲倦。这样想着，我吃完午饭就出发了。\u003c/p\u003e\n\u003cp\u003e一开始打算再去一遍孤山，梅妻鹤子，后来一想还是太冷清了，只怕我看完后会更难过，我选了离我们玉泉校区更近的植物园。于是带着几分自由，几分洒脱，我不慌不忙地走走停停。在24年下半年，高压的备考生活让我开始注意玉泉的景色，斑驳的墙壁，红白砖瓦的屋顶，屋檐上对称的脊兽，一切都在时间的长河里洗过了一遍。无论是百年老树上的苔藓和绿草，还是桂花上附着的雨水，都让我愈加喜欢这个古朴宁静的校区。我顺着智泉路一直往南走，路上碰见许多株梅花，有零星开着的，有簇在一起开得热烈而颇成气候的。\u003c/p\u003e\n\u003cp\u003e从南门出去，沿着青芝坞街道的玉泉路往西行一小会儿，就到了植物园的一个小入口。来玉泉一年半了，我倒是从未料想学校离植物园如此近，也是遗憾没能早来，以往被作业拖累的三点一线的生活还是太让人沮丧了。凭本科学生证，门票只用半价，不过本科要很快结束了。\u003c/p\u003e\n\u003cp\u003e进到植物园内，便感到天地辽阔，大片大片的空白。果然，人还是要经常到没有天花板的地方，在宿舍、教室那样逼仄的地方待时间长了，不免压抑。我没有按照推文里推荐的那般直奔灵峰景区，想着离开前总会去到那，踏上了一条人更少的路。杭州植物园依着西湖山水而建，台阶很多，路边的树大多只剩孤零零的树干，偶有一两株梅花点缀。不知爬了多少级台阶，在我眼前突然浮现出一座曲桥，紧接着是长长的亭廊，往前走是江南园林熟悉的框景，就这样把小岛、湖面全部框起来。环湖一圈，步移景异，意趣横生。\u003c/p\u003e\n\u003cp\u003e正打算原路返回时，看见一块牌匾上写着“玉泉鱼跃”，我不禁想到我校区的名字，难道这之间有什么联系吗？怀着疑问，我继续往前走。进门就有一个大的窗框，后面天井内有湖石一块，翠竹数竿，内有几个庭院，庭院间用回廊、白墙相隔，墙上有漏窗引景，使几个庭院隔而不绝，给人以庭院深深之感。进门后先至玉泉池，名**“鱼乐国”**，池子里数鱼游弋，有巨大的青鱼，还有漂亮的金鱼、鲤鱼，可一饱眼福。还有珍珠泉和晴空细雨泉，可惜今天雾蒙蒙的，没赶上最美的时候。\u003c/p\u003e\n\u003cp\u003e在转了景点一圈后才知道玉泉的历史，玉泉是西湖三大名泉之一，因泉水晶莹透明，犹如美玉而得名。白居易有诗《题玉泉寺》云：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e湛湛玉泉色，悠悠浮云身。闲心对定水，清净两无尘。手把青筇杖，头戴白纶巾。兴尽下山去，知我是谁人。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在“玉泉”的匾额两边有楹联：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e鱼乐机浑忘，泉流玉有声。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e读着这些文字，看着如许景色，真是洗涤心灵。\u003c/p\u003e\n\u003cp\u003e回去看灵峰探梅，灵峰的梅，得一个“满”字。山上山下，漫山遍野，处处是梅林雪海。选一朵花嗅闻，馥郁芬芳，瞬间弥漫在鼻尖，那是梅林深处最纯粹的气息，仿佛将整个冬日的浪漫与温暖，都凝聚在此。\u003c/p\u003e\n\u003cp\u003e走到灵峰最深处，工作人员提醒我已经到了植物园的出口，要么原路返回，要么往山上走。我问山上可以通向哪，他说可以走到老和山，我大喜，真是“山重水复疑无路，柳暗花明又一村”，我知道学校有一个门就可以通向老和山。全然不顾走了两三个小时的疲乏，我只身一人坚定往山上爬去。在山上俯瞰整个杭州，远处是模糊的西湖和雷峰塔，感到前所未有的酣畅，爬山的意义在山顶就这样显现。路上打照面碰见一个四十多岁的叔叔，问他老和山在前面吗，他说是，因为他就是从老和山校门走过来的。感叹巧合之余，不知为何，我脑中想起王维的《终南别业》：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e偶然值林叟，谈笑无还期。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e或许是这字句之间也透着一种随性和偶然的快乐。\u003c/p\u003e\n\u003cp\u003e乘兴而行，意犹未尽，心潮澎湃，遂作此文。\u003c/p\u003e","title":"二月十七日出游杂记"}]