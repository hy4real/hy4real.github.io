[{"content":" 一、整体概述 这是一个完整的MNIST手写数字分类项目，使用PyTorch构建了一个小型卷积神经网络(CNN)。代码实现了数据加载、模型训练、测试评估、可视化错误样本和日志记录的全流程，非常适合作为深度学习入门范例。\n二、逐部分详细解析 1. 导入库 (Lines 1-7) import torch, torchvision, time, os from torch import nn from torch.utils.data import DataLoader from torchvision import datasets, transforms from torch.utils.tensorboard import SummaryWriter import random, numpy as np import matplotlib.pyplot as plt 功能：导入所有必需的工具库。\n设计意图：\ntorch \u0026amp; torchvision: PyTorch核心框架和计算机视觉工具 time, os: 基础系统功能（虽然代码中没直接用，但为扩展预留） SummaryWriter: 连接TensorBoard，实时可视化训练曲线 random, numpy: 用于设置随机种子，保证结果可复现 matplotlib: 绘制错误样本图，直观观察模型弱点 2. 随机种子设置 (Lines 9-16) seed = 42 random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) # CPU 权重 torch.cuda.manual_seed(seed) # GPU 权重 torch.cuda.manual_seed_all(seed) # 多 GPU torch.backends.cudnn.deterministic = True # 卷积确定 torch.backends.cudnn.benchmark = False device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) print(\u0026#34;Using\u0026#34;, device) 功能：强制所有随机性来源产生确定性结果，并自动选择运算设备。\n意图详解：\n可复现性：深度学习实验依赖大量随机初始化，不设置种子的话，每次运行结果都不同，无法对比调参效果 多层保险：分别设置Python、numpy、PyTorch CPU/GPU的随机种子，确保无死角 cuDNN设置： deterministic = True: 牺牲一点速度，确保卷积等操作的算法是确定的 benchmark = False: 禁止自动选择最优算法，避免非确定性 设备选择：自动检测GPU，有则用GPU加速，无则 fallback 到CPU，提升代码兼容性 3. 超参数配置 (Lines 18-21) BATCH_SIZE = 128 EPOCHS = 5 LR = 0.01 功能：集中管理训练参数。\n意图：把可调整的参数放在显眼位置，方便实验时快速修改，避免在代码深处\u0026quot;寻宝\u0026quot;。\n4. 数据加载与预处理 (Lines 23-35) tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) train_ds = datasets.MNIST(root=\u0026#39;data\u0026#39;, train=True, download=True, transform=tf) test_ds = datasets.MNIST(root=\u0026#39;data\u0026#39;, train=False, download=True, transform=tf) # FIX-1: num_workers=0 禁用多进程 train_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True) test_ld = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True) 功能：下载数据集，转换格式，封装成可迭代的数据加载器。\n逐行拆解：\ntransforms.ToTensor(): 将PIL图片(0-255)转为PyTorch张量(0.0-1.0)，并调整维度为[C, H, W] transforms.Normalize((0.1307,), (0.3081,)): 关键步骤，对数据进行标准化 0.1307 是MNIST训练集的均值，0.3081 是标准差 意图：让数据分布接近标准正态分布，加速训练收敛，提升稳定性 为什么是单值？因为MNIST是灰度图，单通道；彩色图会是3个值如(0.5,0.5,0.5) datasets.MNIST(...): 自动从网络下载数据集到./data文件夹 DataLoader : shuffle=True: 训练集打乱顺序，避免模型学到顺序偏见 num_workers=0 : Windows系统下的重要修复。多进程加载数据在Windows上容易因fork机制崩溃，设为0可确保稳定 pin_memory=True: 将数据锁页在内存，加速向GPU的传输 5. 模型定义 (Lines 37-48) class Net(nn.Module): def __init__(self): super().__init__() self.features = nn.Sequential( nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2) ) self.classifier = nn.Sequential( nn.Flatten(), nn.Linear(64*7*7, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 10) ) def forward(self, x): return self.classifier(self.features(x)) 功能：定义一个简洁高效的CNN架构。\n结构解析：\nself.features : 特征提取层 Conv2d(1,32,3,padding=1): 输入1通道(灰度)，输出32通道，3x3卷积，padding=1保持尺寸不变 MaxPool2d(2): 2x2最大池化，尺寸减半（28x28 → 14x14） Conv2d(32,64,3,padding=1): 通道数升维到64 第二次池化后尺寸: 14x14 → 7x7 self.classifier : 分类头 nn.Flatten(): 展平特征图，64*7*7 = 3136个特征 nn.Linear(3136,128): 全连接层降维到128 nn.Dropout(0.2): 防止过拟合，训练时随机丢弃20%神经元 nn.Linear(128,10): 输出10个类别得分（对应数字0-9） 意图：这是经典的LeNet现代化变体，结构清晰，参数少（约20万），在MNIST上足够强大且训练快速。\n6. 训练函数 (Lines 50-61) def train(epoch, model, criterion, optimizer, writer): model.train() for batch_idx, (x, y) in enumerate(train_ld): x, y = x.to(device), y.to(device) optimizer.zero_grad() loss = criterion(model(x), y) loss.backward() optimizer.step() scheduler.step() if batch_idx % 100 == 0: print(f\u0026#39;Epoch {epoch} [{batch_idx*len(x)}/{len(train_ld.dataset)}] \u0026#39; f\u0026#39;Loss: {loss.item():.4f}\u0026#39;) writer.add_scalar(\u0026#39;train/loss\u0026#39;, loss.item(), epoch*len(train_ld)+batch_idx) 功能：执行一个训练轮次，更新模型权重。\n流程详解：\nmodel.train(): 开启训练模式（启用Dropout等） 遍历train_ld，每次取BATCH_SIZE个样本 x.to(device): 把数据搬到GPU/CPU optimizer.zero_grad(): 清空梯度，防止梯度累积 criterion(model(x), y): 前向传播+计算交叉熵损失 loss.backward(): 反向传播，计算梯度 optimizer.step(): 根据梯度更新权重 scheduler.step(): 调整学习率（每个batch都调，注意：通常按epoch调更常见，但这样也行） 每100个batch打印日志，并写入TensorBoard（全局步数=epoch*总batch数+当前batch数） 意图：标准的训练循环，代码紧凑，注释清晰，适合教学。\n7. 测试函数 (Lines 63-98) @torch.no_grad() def test(epoch, model, writer, test_ld, device): model.eval() correct, total = 0, 0 wrong_samples = [] # 存储错误样本的特征（x） wrong_labels = [] # 存储错误样本的真实标签（y） wrong_preds = [] # 存储错误样本的预测标签（pred） # ... 遍历测试集 ... if len(wrong_samples) \u0026gt;= 9: plt.figure(figsize=(9, 9)) for i in range(9): img = wrong_samples[i].squeeze() plt.subplot(3, 3, i + 1) plt.imshow(img, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;T:{label} P:{guess}\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.savefig(\u0026#39;wrong_cases.png\u0026#39;, dpi=120) plt.close() 功能：评估模型性能，并可视化典型错误样本。\n亮点解析：\n@torch.no_grad() : 性能优化，禁用梯度计算，节省内存，提速30%以上 model.eval(): 切换到评估模式（关闭Dropout） 错误样本收集：这是本代码的核心价值之一 只收集9个错误样本，避免内存爆炸 用nonzero(as_tuple=True)[0]找到预测≠真实的索引 存储原始图像、真实标签、预测标签到CPU，便于后续绘图 可视化：绘制3x3网格，展示模型最容易混淆的手写数字 squeeze(): 去除通道维度（1,28,28 → 28,28） cmap='gray': 灰度图显示 plt.close(): 防止内存泄漏，释放图形资源 日志记录：将准确率写入TensorBoard 意图：不仅输出数字指标，还让开发者直观理解模型弱点（比如是7被认成9，还是3被认成8），指导后续改进方向。\n8. 主程序保护壳 (Lines 100-110) if __name__ == \u0026#39;__main__\u0026#39;: from torch.optim.lr_scheduler import CosineAnnealingLR model = Net().to(device) criterion = nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS) writer = SummaryWriter(\u0026#39;runs\u0026#39;) for ep in range(1, EPOCHS+1): train(ep, model, criterion, optimizer, writer) test(ep, model, writer, test_ld, device) torch.save(model.state_dict(), \u0026#39;mnist_cnn.pt\u0026#39;) writer.close() 功能：组织训练流程，保存结果。\n关键点：\nif __name__ == '__main__' : Windows多进程必备。没有这个，在Windows上运行会报错或产生僵尸进程 学习率调度器：CosineAnnealingLR实现余弦退火 学习率从初始值平滑下降到接近0，像cos曲线 意图：前期快速探索，后期精细调整， often 比固定学习率效果好 注意：T_max=EPOCHS表示在整个训练周期内完成一个余弦周期 优化器：SGD with Momentum (momentum=0.9)，经典且有效的组合 模型保存：只保存权重(state_dict)而非整个模型，更轻量且跨平台兼容 writer.close(): 确保日志文件正确写入并释放资源 三、核心设计哲学总结 设计点 意图与价值 确定性训练 让实验可复现，科学调参 Windows兼容 num_workers=0 + if __name__ 确保跨平台稳定 可视化洞察 TensorBoard + 错误样本图，不只是看Loss/Acc，更理解模型行为 模块化 数据、模型、训练、测试分离，便于复用和扩展 防御性编程 检查错误样本数量、及时plt.close()、writer.close()，避免资源泄漏 四、潜在改进建议（供参考） 学习率调度时机：scheduler.step()放在train()的batch循环里，会更频繁调整；若想按epoch调，应移到for ep循环内 早停机制：可添加验证集和早停，防止过拟合 数据增强：MNIST上可加轻微旋转、平移提升鲁棒性 命令行参数：用argparse替代硬编码的超参数，更灵活 ","permalink":"https://hy4real.github.io/posts/deeplearningday1/","summary":"\u003chr\u003e\n\u003ch3 id=\"一整体概述\"\u003e一、整体概述\u003c/h3\u003e\n\u003cp\u003e这是一个\u003cstrong\u003e完整的MNIST手写数字分类项目\u003c/strong\u003e，使用PyTorch构建了一个小型卷积神经网络(CNN)。代码实现了数据加载、模型训练、测试评估、可视化错误样本和日志记录的全流程，非常适合作为深度学习入门范例。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"二逐部分详细解析\"\u003e二、逐部分详细解析\u003c/h3\u003e\n\u003ch4 id=\"1-导入库-lines-1-7\"\u003e\u003cstrong\u003e1. 导入库 (Lines 1-7)\u003c/strong\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003etorchvision\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003etime\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003eos\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003enn\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.utils.data\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eDataLoader\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorchvision\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edatasets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etransforms\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch.utils.tensorboard\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eSummaryWriter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nn\"\u003enumpy\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003enp\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ematplotlib.pyplot\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"nn\"\u003eplt\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e功能\u003c/strong\u003e：导入所有必需的工具库。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e设计意图\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etorch\u003c/code\u003e \u0026amp; \u003ccode\u003etorchvision\u003c/code\u003e: PyTorch核心框架和计算机视觉工具\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etime, os\u003c/code\u003e: 基础系统功能（虽然代码中没直接用，但为扩展预留）\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eSummaryWriter\u003c/code\u003e: 连接TensorBoard，实时可视化训练曲线\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erandom, numpy\u003c/code\u003e: 用于设置随机种子，保证结果可复现\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ematplotlib\u003c/code\u003e: 绘制错误样本图，直观观察模型弱点\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"2-随机种子设置-lines-9-16\"\u003e\u003cstrong\u003e2. 随机种子设置 (Lines 9-16)\u003c/strong\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e42\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003enp\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emanual_seed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e          \u003cspan class=\"c1\"\u003e# CPU 权重\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emanual_seed\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e     \u003cspan class=\"c1\"\u003e# GPU 权重\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emanual_seed_all\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eseed\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 多 GPU\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackends\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecudnn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edeterministic\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e   \u003cspan class=\"c1\"\u003e# 卷积确定\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebackends\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecudnn\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ebenchmark\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;cuda\u0026#34;\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eis_available\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;cpu\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;Using\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e功能\u003c/strong\u003e：\u003cstrong\u003e强制所有随机性来源产生确定性结果\u003c/strong\u003e，并自动选择运算设备。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e意图详解\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e可复现性\u003c/strong\u003e：深度学习实验依赖大量随机初始化，不设置种子的话，每次运行结果都不同，无法对比调参效果\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e多层保险\u003c/strong\u003e：分别设置Python、\u003ccode\u003enumpy\u003c/code\u003e、PyTorch CPU/GPU的随机种子，确保无死角\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ecuDNN设置\u003c/strong\u003e：\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edeterministic = True\u003c/code\u003e: 牺牲一点速度，确保卷积等操作的算法是确定的\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebenchmark = False\u003c/code\u003e: 禁止自动选择最优算法，避免非确定性\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e设备选择\u003c/strong\u003e：自动检测GPU，有则用GPU加速，无则 fallback 到CPU，提升代码兼容性\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4 id=\"3-超参数配置-lines-18-21\"\u003e\u003cstrong\u003e3. 超参数配置 (Lines 18-21)\u003c/strong\u003e\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eBATCH_SIZE\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eEPOCHS\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eLR\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.01\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003e功能\u003c/strong\u003e：集中管理训练参数。\u003c/p\u003e","title":"深度学习入门 Day 1"},{"content":"从合肥到杭州，从紫金港到玉泉，人们或许更容易感受到空间的转换而忽略了时刻流逝的时间，以至于回头看才开始感叹时光荏苒，我的本科四年亦是如此。我尝试着像写论文一样给我的本科写一段摘要、找几个关键词，只不过“话从哪里说起？等到你要说话，什么话都是那样渺茫地找不到个源头”。\n回顾我的本科岁月，很多事我都记不起，我记得的是一些瞬间：比如在团委例会的时刻，比如支教时孩子们的笑脸，比如沉浸在连麦游戏的时光，比如玉泉斑驳的砖瓦、上了苔藓的树干，比如和朋友交心的夜。\n在学校里的时间占了大多数，没有多多感受杭州这座城是我的遗憾。杭州是一个美丽的城市。和部门同学在中秋节清晨登上宝石山看的日出，夜游的西溪湿地，陪高中好友走过的孤山和苏堤，植物园“玉泉”庭院里硕大的金鱼，玉泉后的老和云起，乌龟潭某间亭子里拉二胡的老爷爷，虎跑公园观音殿前的藤萝，灵隐寺从不断绝的清香，九溪烟树望不尽的绿，云雾缭绕的十里琅珰，清幽的云栖竹径，冒雨爬上玉皇山顶后放晴的蓝天……我实在列举不完。我会很想念这里。\n四年前，我听着痛仰乐队的《西湖》来到杭州；三年前，学长推荐，我开始听达达乐队的《南方》。这两首歌贯穿了我的本科生活。\n“那一天那一夜，没有察觉竟已走远；那一天那一夜，从我的故事里走远。”\n“就这样一天天浪漫，这样一天天感叹。没有什么是最重要，日子随着阴晴变换。时间过得飞快，转眼这些已成回忆；每天都有新的问题，不知何时又会再忆起 —— 南方……”\n我想浙大和杭州会成为我永远的南方。\n2025 年 6 月 22 日夜于玉泉 430\n","permalink":"https://hy4real.github.io/posts/gradthoughts/","summary":"\u003cp\u003e从合肥到杭州，从紫金港到玉泉，人们或许更容易感受到空间的转换而忽略了时刻流逝的时间，以至于回头看才开始感叹时光荏苒，我的本科四年亦是如此。我尝试着像写论文一样给我的本科写一段摘要、找几个关键词，只不过“话从哪里说起？等到你要说话，什么话都是那样渺茫地找不到个源头”。\u003c/p\u003e\n\u003cp\u003e回顾我的本科岁月，很多事我都记不起，我记得的是一些瞬间：比如在团委例会的时刻，比如支教时孩子们的笑脸，比如沉浸在连麦游戏的时光，比如玉泉斑驳的砖瓦、上了苔藓的树干，比如和朋友交心的夜。\u003c/p\u003e\n\u003cp\u003e在学校里的时间占了大多数，没有多多感受杭州这座城是我的遗憾。杭州是一个美丽的城市。和部门同学在中秋节清晨登上宝石山看的日出，夜游的西溪湿地，陪高中好友走过的孤山和苏堤，植物园“玉泉”庭院里硕大的金鱼，玉泉后的老和云起，乌龟潭某间亭子里拉二胡的老爷爷，虎跑公园观音殿前的藤萝，灵隐寺从不断绝的清香，九溪烟树望不尽的绿，云雾缭绕的十里琅珰，清幽的云栖竹径，冒雨爬上玉皇山顶后放晴的蓝天……我实在列举不完。我会很想念这里。\u003c/p\u003e\n\u003cp\u003e四年前，我听着痛仰乐队的《西湖》来到杭州；三年前，学长推荐，我开始听达达乐队的《南方》。这两首歌贯穿了我的本科生活。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“那一天那一夜，没有察觉竟已走远；那一天那一夜，从我的故事里走远。”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“就这样一天天浪漫，这样一天天感叹。没有什么是最重要，日子随着阴晴变换。时间过得飞快，转眼这些已成回忆；每天都有新的问题，不知何时又会再忆起 —— 南方……”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e我想浙大和杭州会成为我永远的南方。\u003c/p\u003e\n\u003cp\u003e2025 年 6 月 22 日夜于玉泉 430\u003c/p\u003e","title":"没有察觉，竟已走远"},{"content":"写完毕设以后闲来无事，想着去一趟南京找好兄弟散散心。订好酒店和车票，我在 5 月 14 日的清晨离开杭州，前往南京。\n这并不是我第一次去南京，以前上初中时候周末去过一次，从合肥坐大巴车要花费一上午时间才到达那里，下午爬了一下中山陵，看了一下南京古城墙，就回去了。现在并不记得当时的细节了，只记得带回来一块刻着“天才在于勤奋，聪明在于积累”的雨花石，以及中山陵那望不到头的一级级楼梯。\n见到朋友以后很开心。我把行李放好后，就听他的指示到一个又一个景点去。\n先是颐和路周围，粉刷的不黄不白的墙，偶尔开在墙边的一株两株花朵，不成规模的行道树，这竟然就被某些人趋之若鹜称为景点，还有人排队拍照。我叹为观止。\n紧接着是去先锋书店，一个地下车库改造的网红书店，在书店的某个区域里，悬挂着别人写下心情与故事的明信片。确实也对得上网红一词，在一堆明信片里找到一份求而不得的心碎瞬间，配上一首伤感的降速降调情歌，一个抖音大爆单视频就做好了。或许这不是书店的问题，或许也不仅仅是书店的问题，我只是习惯抱怨、习惯感叹。\n玄武湖挺让人失望的，明明有皇家园林的身份做背书，呈现出的效果却并非如此：小孩子才喜欢的鸭子造型的载人船，不开门的游乐园，莫名其妙响起来的流行音乐……我不知道为什么要这样去设计一个景点，无论是商业化还是别的方面都很难让人认可。\n下午的南大鼓楼校区是蛮好的，静静的，嚼得菜根，做得大事。\n鸡鸣寺应该是仗着自己在南京的名声比较好，所以无论是门票还是周边文创的价格都比灵隐和法喜贵两三倍。给人祈祷点香火的炉子竟然是一个没有顶的大炉子，虔诚的信徒只能把三根香远远地投进去，不知道是在上香还是投标枪。\n晚上我们去了夫子庙和秦淮河，目光所及之处游人如织，金碧辉煌的布置。本来抱着“泛舟于河上”的幻想，看见现代化的游船载着几十人快速地从身边呼啸而过，我便说不出话了，这和在《桨声灯影里的秦淮河》真是截然不同了：\n从两重玻璃里映出那辐射着的黄黄的散光，反晕出一片朦胧的烟霭；透过这烟霭，在黯黯的水波里，又逗起缕缕的明漪。在这薄霭和微漪里，听着那悠然的间歇的桨声，谁能不被引入他的美梦去呢？\n第二天去了仙林校区，整体设计是很符合学生生活学习的，这点上比紫金港做得要好。\n下午的明孝陵挺惊喜的，景色引人，五彩缤纷的花朵，自由自在的天鹅和野鸭，性情温顺的梅花鹿，可惜是来的季节并不完美，错过了春天的樱花展和冬天的梅花园。\n从明孝陵出来，顺着翠绿的朦胧的梧桐大道往上走，简单参观了一下美龄宫和音乐台，并没有特别的感受。\n需要多提一嘴，在南京的多个景区，我都会碰见主动上前揽客的人，或者问我们需不需要拍照，或者问我们需不需要租车，不能否认他们迎合了很多人的需求，如果没有市场，想必他们也不会以此为生意，但是有人喜欢就有人讨厌——对于一个在杭州待了快四年的人，我实在难以接受这种没有管制的景点。在秦淮河畔，听见了以下的一段对话：“刚刚我碰到个游客，他说有人拍照只收十块钱。”“是谁只收十块钱的？你全家死了。”我和朋友忍俊不禁。\n在六朝古都的两天两夜，我却并没有感觉到任何古色古香的沉淀，感受最大的竟是浮躁，不知道是不是一种讽刺。朋友说我是被杭州和西湖惯坏了，或许确实如此，我对杭州和西湖寄托太多感情了。\n今天是朋友的生日，我在这里祝他生日快乐。今年秋天他会来浙大读研，虽然是在萧山的水博园，位置很偏僻，但我希望他能在杭州的三年时间充分感受这座城市。也许他会在之后理解我游览南京之后的感受。\n2025年5月16日于杭州\n","permalink":"https://hy4real.github.io/posts/nanjingtour/","summary":"\u003cp\u003e写完毕设以后闲来无事，想着去一趟南京找好兄弟散散心。订好酒店和车票，我在 5 月 14 日的清晨离开杭州，前往南京。\u003c/p\u003e\n\u003cp\u003e这并不是我第一次去南京，以前上初中时候周末去过一次，从合肥坐大巴车要花费一上午时间才到达那里，下午爬了一下中山陵，看了一下南京古城墙，就回去了。现在并不记得当时的细节了，只记得带回来一块刻着“天才在于勤奋，聪明在于积累”的雨花石，以及中山陵那望不到头的一级级楼梯。\u003c/p\u003e\n\u003cp\u003e见到朋友以后很开心。我把行李放好后，就听他的指示到一个又一个景点去。\u003c/p\u003e\n\u003cp\u003e先是颐和路周围，粉刷的不黄不白的墙，偶尔开在墙边的一株两株花朵，不成规模的行道树，这竟然就被某些人趋之若鹜称为景点，还有人排队拍照。我叹为观止。\u003c/p\u003e\n\u003cp\u003e紧接着是去先锋书店，一个地下车库改造的网红书店，在书店的某个区域里，悬挂着别人写下心情与故事的明信片。确实也对得上网红一词，在一堆明信片里找到一份求而不得的心碎瞬间，配上一首伤感的降速降调情歌，一个抖音大爆单视频就做好了。或许这不是书店的问题，或许也不仅仅是书店的问题，我只是习惯抱怨、习惯感叹。\u003c/p\u003e\n\u003cp\u003e玄武湖挺让人失望的，明明有皇家园林的身份做背书，呈现出的效果却并非如此：小孩子才喜欢的鸭子造型的载人船，不开门的游乐园，莫名其妙响起来的流行音乐……我不知道为什么要这样去设计一个景点，无论是商业化还是别的方面都很难让人认可。\u003c/p\u003e\n\u003cp\u003e下午的南大鼓楼校区是蛮好的，静静的，嚼得菜根，做得大事。\u003c/p\u003e\n\u003cp\u003e鸡鸣寺应该是仗着自己在南京的名声比较好，所以无论是门票还是周边文创的价格都比灵隐和法喜贵两三倍。给人祈祷点香火的炉子竟然是一个没有顶的大炉子，虔诚的信徒只能把三根香远远地投进去，不知道是在上香还是投标枪。\u003c/p\u003e\n\u003cp\u003e晚上我们去了夫子庙和秦淮河，目光所及之处游人如织，金碧辉煌的布置。本来抱着“泛舟于河上”的幻想，看见现代化的游船载着几十人快速地从身边呼啸而过，我便说不出话了，这和在《桨声灯影里的秦淮河》真是截然不同了：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e从两重玻璃里映出那辐射着的黄黄的散光，反晕出一片朦胧的烟霭；透过这烟霭，在黯黯的水波里，又逗起缕缕的明漪。在这薄霭和微漪里，听着那悠然的间歇的桨声，谁能不被引入他的美梦去呢？\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e第二天去了仙林校区，整体设计是很符合学生生活学习的，这点上比紫金港做得要好。\u003c/p\u003e\n\u003cp\u003e下午的明孝陵挺惊喜的，景色引人，五彩缤纷的花朵，自由自在的天鹅和野鸭，性情温顺的梅花鹿，可惜是来的季节并不完美，错过了春天的樱花展和冬天的梅花园。\u003c/p\u003e\n\u003cp\u003e从明孝陵出来，顺着翠绿的朦胧的梧桐大道往上走，简单参观了一下美龄宫和音乐台，并没有特别的感受。\u003c/p\u003e\n\u003cp\u003e需要多提一嘴，在南京的多个景区，我都会碰见主动上前揽客的人，或者问我们需不需要拍照，或者问我们需不需要租车，不能否认他们迎合了很多人的需求，如果没有市场，想必他们也不会以此为生意，但是有人喜欢就有人讨厌——对于一个在杭州待了快四年的人，我实在难以接受这种没有管制的景点。在秦淮河畔，听见了以下的一段对话：“刚刚我碰到个游客，他说有人拍照只收十块钱。”“是谁只收十块钱的？你全家死了。”我和朋友忍俊不禁。\u003c/p\u003e\n\u003cp\u003e在六朝古都的两天两夜，我却并没有感觉到任何古色古香的沉淀，感受最大的竟是浮躁，不知道是不是一种讽刺。朋友说我是被杭州和西湖惯坏了，或许确实如此，我对杭州和西湖寄托太多感情了。\u003c/p\u003e\n\u003cp\u003e今天是朋友的生日，我在这里祝他生日快乐。今年秋天他会来浙大读研，虽然是在萧山的水博园，位置很偏僻，但我希望他能在杭州的三年时间充分感受这座城市。也许他会在之后理解我游览南京之后的感受。\u003c/p\u003e\n\u003cp\u003e2025年5月16日于杭州\u003c/p\u003e","title":"金陵游"},{"content":"自从去年十二月底考研初试结束以后，原本以为可以如释重负，然而达摩克里斯之剑好像只是掉下来了一点，更加让人焦虑。在新学期的第一天，我原本打算继续在寝室里，准备着毕设和复试的琐碎事情，继续被接连不断的截止日期所驱动，然而中午在微信里看到了西湖旅游的推文：《2025年西湖第一场花事》，心里便想着给自己放个假，一次独属自己的假期，而不用像寒假那样走亲访友的疲倦。这样想着，我吃完午饭就出发了。\n一开始打算再去一遍孤山，梅妻鹤子，后来一想还是太冷清了，只怕我看完后会更难过，我选了离我们玉泉校区更近的植物园。于是带着几分自由，几分洒脱，我不慌不忙地走走停停。在24年下半年，高压的备考生活让我开始注意玉泉的景色，斑驳的墙壁，红白砖瓦的屋顶，屋檐上对称的脊兽，一切都在时间的长河里洗过了一遍。无论是百年老树上的苔藓和绿草，还是桂花上附着的雨水，都让我愈加喜欢这个古朴宁静的校区。我顺着智泉路一直往南走，路上碰见许多株梅花，有零星开着的，有簇在一起开得热烈而颇成气候的。\n从南门出去，沿着青芝坞街道的玉泉路往西行一小会儿，就到了植物园的一个小入口。来玉泉一年半了，我倒是从未料想学校离植物园如此近，也是遗憾没能早来，以往被作业拖累的三点一线的生活还是太让人沮丧了。凭本科学生证，门票只用半价，不过本科要很快结束了。\n进到植物园内，便感到天地辽阔，大片大片的空白。果然，人还是要经常到没有天花板的地方，在宿舍、教室那样逼仄的地方待时间长了，不免压抑。我没有按照推文里推荐的那般直奔灵峰景区，想着离开前总会去到那，踏上了一条人更少的路。杭州植物园依着西湖山水而建，台阶很多，路边的树大多只剩孤零零的树干，偶有一两株梅花点缀。不知爬了多少级台阶，在我眼前突然浮现出一座曲桥，紧接着是长长的亭廊，往前走是江南园林熟悉的框景，就这样把小岛、湖面全部框起来。环湖一圈，步移景异，意趣横生。\n正打算原路返回时，看见一块牌匾上写着“玉泉鱼跃”，我不禁想到我校区的名字，难道这之间有什么联系吗？怀着疑问，我继续往前走。进门就有一个大的窗框，后面天井内有湖石一块，翠竹数竿，内有几个庭院，庭院间用回廊、白墙相隔，墙上有漏窗引景，使几个庭院隔而不绝，给人以庭院深深之感。进门后先至玉泉池，名**“鱼乐国”**，池子里数鱼游弋，有巨大的青鱼，还有漂亮的金鱼、鲤鱼，可一饱眼福。还有珍珠泉和晴空细雨泉，可惜今天雾蒙蒙的，没赶上最美的时候。\n在转了景点一圈后才知道玉泉的历史，玉泉是西湖三大名泉之一，因泉水晶莹透明，犹如美玉而得名。白居易有诗《题玉泉寺》云：\n湛湛玉泉色，悠悠浮云身。闲心对定水，清净两无尘。手把青筇杖，头戴白纶巾。兴尽下山去，知我是谁人。\n在“玉泉”的匾额两边有楹联：\n鱼乐机浑忘，泉流玉有声。\n读着这些文字，看着如许景色，真是洗涤心灵。\n回去看灵峰探梅，灵峰的梅，得一个“满”字。山上山下，漫山遍野，处处是梅林雪海。选一朵花嗅闻，馥郁芬芳，瞬间弥漫在鼻尖，那是梅林深处最纯粹的气息，仿佛将整个冬日的浪漫与温暖，都凝聚在此。\n走到灵峰最深处，工作人员提醒我已经到了植物园的出口，要么原路返回，要么往山上走。我问山上可以通向哪，他说可以走到老和山，我大喜，真是“山重水复疑无路，柳暗花明又一村”，我知道学校有一个门就可以通向老和山。全然不顾走了两三个小时的疲乏，我只身一人坚定往山上爬去。在山上俯瞰整个杭州，远处是模糊的西湖和雷峰塔，感到前所未有的酣畅，爬山的意义在山顶就这样显现。路上打照面碰见一个四十多岁的叔叔，问他老和山在前面吗，他说是，因为他就是从老和山校门走过来的。感叹巧合之余，不知为何，我脑中想起王维的《终南别业》：\n偶然值林叟，谈笑无还期。\n或许是这字句之间也透着一种随性和偶然的快乐。\n乘兴而行，意犹未尽，心潮澎湃，遂作此文。\n","permalink":"https://hy4real.github.io/posts/feb.17th/","summary":"\u003cp\u003e自从去年十二月底考研初试结束以后，原本以为可以如释重负，然而达摩克里斯之剑好像只是掉下来了一点，更加让人焦虑。在新学期的第一天，我原本打算继续在寝室里，准备着毕设和复试的琐碎事情，继续被接连不断的截止日期所驱动，然而中午在微信里看到了西湖旅游的推文：《2025年西湖第一场花事》，心里便想着给自己放个假，一次独属自己的假期，而不用像寒假那样走亲访友的疲倦。这样想着，我吃完午饭就出发了。\u003c/p\u003e\n\u003cp\u003e一开始打算再去一遍孤山，梅妻鹤子，后来一想还是太冷清了，只怕我看完后会更难过，我选了离我们玉泉校区更近的植物园。于是带着几分自由，几分洒脱，我不慌不忙地走走停停。在24年下半年，高压的备考生活让我开始注意玉泉的景色，斑驳的墙壁，红白砖瓦的屋顶，屋檐上对称的脊兽，一切都在时间的长河里洗过了一遍。无论是百年老树上的苔藓和绿草，还是桂花上附着的雨水，都让我愈加喜欢这个古朴宁静的校区。我顺着智泉路一直往南走，路上碰见许多株梅花，有零星开着的，有簇在一起开得热烈而颇成气候的。\u003c/p\u003e\n\u003cp\u003e从南门出去，沿着青芝坞街道的玉泉路往西行一小会儿，就到了植物园的一个小入口。来玉泉一年半了，我倒是从未料想学校离植物园如此近，也是遗憾没能早来，以往被作业拖累的三点一线的生活还是太让人沮丧了。凭本科学生证，门票只用半价，不过本科要很快结束了。\u003c/p\u003e\n\u003cp\u003e进到植物园内，便感到天地辽阔，大片大片的空白。果然，人还是要经常到没有天花板的地方，在宿舍、教室那样逼仄的地方待时间长了，不免压抑。我没有按照推文里推荐的那般直奔灵峰景区，想着离开前总会去到那，踏上了一条人更少的路。杭州植物园依着西湖山水而建，台阶很多，路边的树大多只剩孤零零的树干，偶有一两株梅花点缀。不知爬了多少级台阶，在我眼前突然浮现出一座曲桥，紧接着是长长的亭廊，往前走是江南园林熟悉的框景，就这样把小岛、湖面全部框起来。环湖一圈，步移景异，意趣横生。\u003c/p\u003e\n\u003cp\u003e正打算原路返回时，看见一块牌匾上写着“玉泉鱼跃”，我不禁想到我校区的名字，难道这之间有什么联系吗？怀着疑问，我继续往前走。进门就有一个大的窗框，后面天井内有湖石一块，翠竹数竿，内有几个庭院，庭院间用回廊、白墙相隔，墙上有漏窗引景，使几个庭院隔而不绝，给人以庭院深深之感。进门后先至玉泉池，名**“鱼乐国”**，池子里数鱼游弋，有巨大的青鱼，还有漂亮的金鱼、鲤鱼，可一饱眼福。还有珍珠泉和晴空细雨泉，可惜今天雾蒙蒙的，没赶上最美的时候。\u003c/p\u003e\n\u003cp\u003e在转了景点一圈后才知道玉泉的历史，玉泉是西湖三大名泉之一，因泉水晶莹透明，犹如美玉而得名。白居易有诗《题玉泉寺》云：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e湛湛玉泉色，悠悠浮云身。闲心对定水，清净两无尘。手把青筇杖，头戴白纶巾。兴尽下山去，知我是谁人。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在“玉泉”的匾额两边有楹联：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e鱼乐机浑忘，泉流玉有声。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e读着这些文字，看着如许景色，真是洗涤心灵。\u003c/p\u003e\n\u003cp\u003e回去看灵峰探梅，灵峰的梅，得一个“满”字。山上山下，漫山遍野，处处是梅林雪海。选一朵花嗅闻，馥郁芬芳，瞬间弥漫在鼻尖，那是梅林深处最纯粹的气息，仿佛将整个冬日的浪漫与温暖，都凝聚在此。\u003c/p\u003e\n\u003cp\u003e走到灵峰最深处，工作人员提醒我已经到了植物园的出口，要么原路返回，要么往山上走。我问山上可以通向哪，他说可以走到老和山，我大喜，真是“山重水复疑无路，柳暗花明又一村”，我知道学校有一个门就可以通向老和山。全然不顾走了两三个小时的疲乏，我只身一人坚定往山上爬去。在山上俯瞰整个杭州，远处是模糊的西湖和雷峰塔，感到前所未有的酣畅，爬山的意义在山顶就这样显现。路上打照面碰见一个四十多岁的叔叔，问他老和山在前面吗，他说是，因为他就是从老和山校门走过来的。感叹巧合之余，不知为何，我脑中想起王维的《终南别业》：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e偶然值林叟，谈笑无还期。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e或许是这字句之间也透着一种随性和偶然的快乐。\u003c/p\u003e\n\u003cp\u003e乘兴而行，意犹未尽，心潮澎湃，遂作此文。\u003c/p\u003e","title":"二月十七日出游杂记"}]